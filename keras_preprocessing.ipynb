{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_class_data_loader import MultiClassDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MultiClassDataLoader(tf.flags, Tokenizer())\n",
    "data_loader.define_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x0000028FBE957F98>\n",
      "ALSOLOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x0000028FB914EE80>\n",
      "BATCH_SIZE=<absl.flags._flag.Flag object at 0x0000028FBE957D68>\n",
      "CHECKPOINT_EVERY=<absl.flags._flag.Flag object at 0x0000028FBE957F60>\n",
      "CLASS_DATA_FILE=<absl.flags._flag.Flag object at 0x0000028FBE965240>\n",
      "DEV_DATA_FILE=<absl.flags._flag.Flag object at 0x0000028FBE9651D0>\n",
      "DROPOUT_KEEP_PROB=<absl.flags._flag.Flag object at 0x0000028FBE957C18>\n",
      "EMBEDDING_DIM=<absl.flags._flag.Flag object at 0x0000028FA01CE9B0>\n",
      "EVALUATE_EVERY=<absl.flags._flag.Flag object at 0x0000028FBE957EB8>\n",
      "FILTER_SIZES=<absl.flags._flag.Flag object at 0x0000028FBE957860>\n",
      "L2_REG_LAMBDA=<absl.flags._flag.Flag object at 0x0000028FBE957CC0>\n",
      "LOG_DEVICE_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x0000028FBE965080>\n",
      "LOG_DIR=<absl.flags._flag.Flag object at 0x0000028FB9156EB8>\n",
      "LOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x0000028FB914EAC8>\n",
      "NUM_EPOCHS=<absl.flags._flag.Flag object at 0x0000028FBE957E10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-12 11:35:43.555634: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
      "2020-06-12 11:35:43.555912: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2020-06-12 11:35:45.696596: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_FILTERS=<absl.flags._flag.Flag object at 0x0000028FBE957B38>\n",
      "ONLY_CHECK_ARGS=<absl.flags._flag.BooleanFlag object at 0x0000028FB915E6D8>\n",
      "OP_CONVERSION_FALLBACK_TO_WHILE_LOOP=<absl.flags._flag.BooleanFlag object at 0x0000028FBB603710>\n",
      "PDB_POST_MORTEM=<absl.flags._flag.BooleanFlag object at 0x0000028FB914E1D0>\n",
      "PROFILE_FILE=<absl.flags._flag.Flag object at 0x0000028FB915E630>\n",
      "RUN_WITH_PDB=<absl.flags._flag.BooleanFlag object at 0x0000028FB8F0DF98>\n",
      "RUN_WITH_PROFILING=<absl.flags._flag.BooleanFlag object at 0x0000028FB915E588>\n",
      "SHOWPREFIXFORINFO=<absl.flags._flag.BooleanFlag object at 0x0000028FB915E160>\n",
      "STDERRTHRESHOLD=<absl.logging._StderrthresholdFlag object at 0x0000028FB915E048>\n",
      "TEST_RANDOM_SEED=<absl.flags._flag.Flag object at 0x0000028FBC851668>\n",
      "TEST_RANDOMIZE_ORDERING_SEED=<absl.flags._flag.Flag object at 0x0000028FBC865CF8>\n",
      "TEST_SRCDIR=<absl.flags._flag.Flag object at 0x0000028FBC8517B8>\n",
      "TEST_TMPDIR=<absl.flags._flag.Flag object at 0x0000028FBC851940>\n",
      "TRAIN_DATA_FILE=<absl.flags._flag.Flag object at 0x0000028FBE965160>\n",
      "USE_CPROFILE_FOR_PROFILING=<absl.flags._flag.BooleanFlag object at 0x0000028FB915E668>\n",
      "V=<absl.logging._VerbosityFlag object at 0x0000028FB9156F28>\n",
      "VERBOSITY=<absl.logging._VerbosityFlag object at 0x0000028FB9156F28>\n",
      "XML_OUTPUT_FILE=<absl.flags._flag.Flag object at 0x0000028FBC865240>\n",
      "\n",
      "Loading data...\n",
      "Vocabulary Size: 3362\n",
      "Train/Dev split: 300/30\n",
      "filter_size = 3\n",
      "filter_size = 4\n",
      "filter_size = 5\n",
      "Writing to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\n",
      "\n",
      "2020-06-12T11:35:49.159611: step 1, loss 5.1623, acc 0.359375\n",
      "2020-06-12T11:35:50.585756: step 2, loss 3.2973, acc 0.359375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-06-12 11:35:45.701916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n",
      "2020-06-12 11:35:45.801013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-06-12 11:35:45.803736: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
      "2020-06-12 11:35:45.806435: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_100.dll'; dlerror: cublas64_100.dll not found\n",
      "2020-06-12 11:35:45.808827: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_100.dll'; dlerror: cufft64_100.dll not found\n",
      "2020-06-12 11:35:45.811425: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_100.dll'; dlerror: curand64_100.dll not found\n",
      "2020-06-12 11:35:45.813605: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_100.dll'; dlerror: cusolver64_100.dll not found\n",
      "2020-06-12 11:35:45.816158: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_100.dll'; dlerror: cusparse64_100.dll not found\n",
      "2020-06-12 11:35:46.021976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-06-12 11:35:46.022310: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2020-06-12 11:35:46.125239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-06-12 11:35:46.125466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-06-12 11:35:46.125601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "WARNING:tensorflow:From D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\text_cnn.py:64: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\text_cnn.py:80: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kkk\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-06-12T11:35:52.027940: step 3, loss 3.7369, acc 0.25\n",
      "2020-06-12T11:35:53.443116: step 4, loss 3.68847, acc 0.3125\n",
      "2020-06-12T11:35:54.458401: step 5, loss 2.9376, acc 0.409091\n",
      "2020-06-12T11:35:55.995290: step 6, loss 3.77549, acc 0.375\n",
      "2020-06-12T11:35:57.560107: step 7, loss 2.80174, acc 0.34375\n",
      "2020-06-12T11:35:59.105980: step 8, loss 3.10183, acc 0.4375\n",
      "2020-06-12T11:36:00.599979: step 9, loss 2.93476, acc 0.46875\n",
      "2020-06-12T11:36:01.679093: step 10, loss 2.34684, acc 0.454545\n",
      "2020-06-12T11:36:03.157139: step 11, loss 2.60918, acc 0.375\n",
      "2020-06-12T11:36:04.682135: step 12, loss 2.72767, acc 0.46875\n",
      "2020-06-12T11:36:06.166093: step 13, loss 2.43334, acc 0.359375\n",
      "2020-06-12T11:36:07.672109: step 14, loss 2.06593, acc 0.484375\n",
      "2020-06-12T11:36:08.716275: step 15, loss 2.17096, acc 0.409091\n",
      "2020-06-12T11:36:10.195384: step 16, loss 2.59608, acc 0.40625\n",
      "2020-06-12T11:36:11.724232: step 17, loss 2.46187, acc 0.4375\n",
      "2020-06-12T11:36:13.236190: step 18, loss 2.13259, acc 0.53125\n",
      "2020-06-12T11:36:14.810978: step 19, loss 2.10587, acc 0.484375\n",
      "2020-06-12T11:36:15.870145: step 20, loss 2.34604, acc 0.386364\n",
      "2020-06-12T11:36:17.425986: step 21, loss 2.0121, acc 0.46875\n",
      "2020-06-12T11:36:18.939937: step 22, loss 2.01084, acc 0.546875\n",
      "2020-06-12T11:36:20.477826: step 23, loss 1.38797, acc 0.59375\n",
      "2020-06-12T11:36:22.036658: step 24, loss 1.87799, acc 0.59375\n",
      "2020-06-12T11:36:23.067971: step 25, loss 1.67447, acc 0.681818\n",
      "2020-06-12T11:36:24.595814: step 26, loss 1.38532, acc 0.59375\n",
      "2020-06-12T11:36:26.121734: step 27, loss 1.98489, acc 0.4375\n",
      "2020-06-12T11:36:27.643665: step 28, loss 1.86864, acc 0.515625\n",
      "2020-06-12T11:36:29.203493: step 29, loss 1.11599, acc 0.6875\n",
      "2020-06-12T11:36:30.326531: step 30, loss 0.88015, acc 0.704545\n",
      "2020-06-12T11:36:31.866373: step 31, loss 1.36197, acc 0.640625\n",
      "2020-06-12T11:36:33.435177: step 32, loss 1.179, acc 0.65625\n",
      "2020-06-12T11:36:34.961097: step 33, loss 1.40947, acc 0.71875\n",
      "2020-06-12T11:36:36.455101: step 34, loss 1.37389, acc 0.578125\n",
      "2020-06-12T11:36:37.519257: step 35, loss 1.70394, acc 0.545455\n",
      "2020-06-12T11:36:39.039234: step 36, loss 1.18835, acc 0.6875\n",
      "2020-06-12T11:36:40.567108: step 37, loss 0.801603, acc 0.75\n",
      "2020-06-12T11:36:42.089036: step 38, loss 1.05203, acc 0.640625\n",
      "2020-06-12T11:36:43.614957: step 39, loss 1.38729, acc 0.609375\n",
      "2020-06-12T11:36:44.689086: step 40, loss 1.10378, acc 0.704545\n",
      "2020-06-12T11:36:46.301772: step 41, loss 0.821714, acc 0.765625\n",
      "2020-06-12T11:36:47.866589: step 42, loss 1.02125, acc 0.703125\n",
      "2020-06-12T11:36:49.394503: step 43, loss 1.07039, acc 0.640625\n",
      "2020-06-12T11:36:50.912444: step 44, loss 1.02472, acc 0.71875\n",
      "2020-06-12T11:36:51.984578: step 45, loss 0.759012, acc 0.818182\n",
      "2020-06-12T11:36:53.503516: step 46, loss 1.48156, acc 0.625\n",
      "2020-06-12T11:36:55.064342: step 47, loss 0.998784, acc 0.78125\n",
      "2020-06-12T11:36:56.588266: step 48, loss 0.58519, acc 0.78125\n",
      "2020-06-12T11:36:58.153083: step 49, loss 1.15043, acc 0.640625\n",
      "2020-06-12T11:36:59.211253: step 50, loss 1.11094, acc 0.727273\n",
      "2020-06-12T11:37:00.727201: step 51, loss 0.988034, acc 0.640625\n",
      "2020-06-12T11:37:02.328917: step 52, loss 1.04892, acc 0.71875\n",
      "2020-06-12T11:37:03.846858: step 53, loss 0.47735, acc 0.828125\n",
      "2020-06-12T11:37:05.430623: step 54, loss 0.886533, acc 0.703125\n",
      "2020-06-12T11:37:06.487797: step 55, loss 0.775398, acc 0.727273\n",
      "2020-06-12T11:37:08.077546: step 56, loss 0.975673, acc 0.703125\n",
      "2020-06-12T11:37:09.570595: step 57, loss 0.680379, acc 0.75\n",
      "2020-06-12T11:37:11.062563: step 58, loss 0.676618, acc 0.78125\n",
      "2020-06-12T11:37:12.544599: step 59, loss 0.530183, acc 0.78125\n",
      "2020-06-12T11:37:13.583822: step 60, loss 0.975118, acc 0.727273\n",
      "2020-06-12T11:37:15.122705: step 61, loss 0.920945, acc 0.71875\n",
      "2020-06-12T11:37:16.632670: step 62, loss 0.742366, acc 0.765625\n",
      "2020-06-12T11:37:18.225410: step 63, loss 0.919184, acc 0.734375\n",
      "2020-06-12T11:37:19.725476: step 64, loss 0.243887, acc 0.921875\n",
      "2020-06-12T11:37:20.788555: step 65, loss 0.840903, acc 0.681818\n",
      "2020-06-12T11:37:22.339460: step 66, loss 0.384544, acc 0.890625\n",
      "2020-06-12T11:37:23.833414: step 67, loss 0.282815, acc 0.875\n",
      "2020-06-12T11:37:25.352353: step 68, loss 0.732686, acc 0.796875\n",
      "2020-06-12T11:37:26.847355: step 69, loss 0.63317, acc 0.78125\n",
      "2020-06-12T11:37:27.861643: step 70, loss 0.786405, acc 0.75\n",
      "2020-06-12T11:37:29.347670: step 71, loss 0.599941, acc 0.8125\n",
      "2020-06-12T11:37:30.860624: step 72, loss 0.477537, acc 0.828125\n",
      "2020-06-12T11:37:32.394521: step 73, loss 0.505573, acc 0.90625\n",
      "2020-06-12T11:37:33.944379: step 74, loss 0.462476, acc 0.921875\n",
      "2020-06-12T11:37:35.023492: step 75, loss 0.493271, acc 0.840909\n",
      "2020-06-12T11:37:36.521487: step 76, loss 0.278834, acc 0.84375\n",
      "2020-06-12T11:37:38.038466: step 77, loss 0.884509, acc 0.734375\n",
      "2020-06-12T11:37:39.531437: step 78, loss 0.513261, acc 0.84375\n",
      "2020-06-12T11:37:41.018462: step 79, loss 0.628825, acc 0.84375\n",
      "2020-06-12T11:37:42.072644: step 80, loss 0.436961, acc 0.863636\n",
      "2020-06-12T11:37:43.536727: step 81, loss 0.269829, acc 0.859375\n",
      "2020-06-12T11:37:45.052675: step 82, loss 0.573363, acc 0.8125\n",
      "2020-06-12T11:37:46.505788: step 83, loss 0.538948, acc 0.8125\n",
      "2020-06-12T11:37:47.989821: step 84, loss 0.372917, acc 0.84375\n",
      "2020-06-12T11:37:49.130770: step 85, loss 0.231438, acc 0.931818\n",
      "2020-06-12T11:37:50.692594: step 86, loss 0.535753, acc 0.8125\n",
      "2020-06-12T11:37:52.206546: step 87, loss 0.411542, acc 0.875\n",
      "2020-06-12T11:37:53.742480: step 88, loss 0.617144, acc 0.828125\n",
      "2020-06-12T11:37:55.270354: step 89, loss 0.332488, acc 0.84375\n",
      "2020-06-12T11:37:56.291680: step 90, loss 0.390657, acc 0.886364\n",
      "2020-06-12T11:37:57.844543: step 91, loss 0.492755, acc 0.796875\n",
      "2020-06-12T11:37:59.359418: step 92, loss 0.23657, acc 0.90625\n",
      "2020-06-12T11:38:00.863439: step 93, loss 0.40379, acc 0.84375\n",
      "2020-06-12T11:38:02.411257: step 94, loss 0.399018, acc 0.859375\n",
      "2020-06-12T11:38:03.464441: step 95, loss 0.498225, acc 0.795455\n",
      "2020-06-12T11:38:04.996362: step 96, loss 0.336543, acc 0.859375\n",
      "2020-06-12T11:38:06.566190: step 97, loss 0.284339, acc 0.890625\n",
      "2020-06-12T11:38:08.038264: step 98, loss 0.57162, acc 0.875\n",
      "2020-06-12T11:38:09.576100: step 99, loss 0.314661, acc 0.84375\n",
      "2020-06-12T11:38:10.607341: step 100, loss 0.216541, acc 0.886364\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:38:10.750958: step 100, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-100\n",
      "\n",
      "2020-06-12T11:38:12.738644: step 101, loss 0.352872, acc 0.8125\n",
      "2020-06-12T11:38:14.222675: step 102, loss 0.331127, acc 0.875\n",
      "2020-06-12T11:38:15.726654: step 103, loss 0.409898, acc 0.890625\n",
      "2020-06-12T11:38:17.214676: step 104, loss 0.516646, acc 0.84375\n",
      "2020-06-12T11:38:18.271906: step 105, loss 0.550807, acc 0.909091\n",
      "2020-06-12T11:38:19.753884: step 106, loss 0.854406, acc 0.765625\n",
      "2020-06-12T11:38:21.296759: step 107, loss 0.23148, acc 0.890625\n",
      "2020-06-12T11:38:22.799811: step 108, loss 0.264473, acc 0.90625\n",
      "2020-06-12T11:38:24.307707: step 109, loss 0.323815, acc 0.875\n",
      "2020-06-12T11:38:25.369867: step 110, loss 0.626487, acc 0.818182\n",
      "2020-06-12T11:38:26.828965: step 111, loss 0.400743, acc 0.875\n",
      "2020-06-12T11:38:28.341921: step 112, loss 0.289218, acc 0.875\n",
      "2020-06-12T11:38:29.827947: step 113, loss 0.406565, acc 0.78125\n",
      "2020-06-12T11:38:31.345956: step 114, loss 0.235332, acc 0.890625\n",
      "2020-06-12T11:38:32.377201: step 115, loss 0.381291, acc 0.795455\n",
      "2020-06-12T11:38:33.855178: step 116, loss 0.263503, acc 0.890625\n",
      "2020-06-12T11:38:35.336217: step 117, loss 0.130541, acc 0.9375\n",
      "2020-06-12T11:38:36.847177: step 118, loss 0.169544, acc 0.9375\n",
      "2020-06-12T11:38:38.424958: step 119, loss 0.192873, acc 0.96875\n",
      "2020-06-12T11:38:39.464180: step 120, loss 0.166463, acc 0.909091\n",
      "2020-06-12T11:38:40.980126: step 121, loss 0.395955, acc 0.84375\n",
      "2020-06-12T11:38:42.448201: step 122, loss 0.548385, acc 0.828125\n",
      "2020-06-12T11:38:43.930239: step 123, loss 0.221072, acc 0.9375\n",
      "2020-06-12T11:38:45.450174: step 124, loss 0.330547, acc 0.875\n",
      "2020-06-12T11:38:46.474483: step 125, loss 0.206645, acc 0.931818\n",
      "2020-06-12T11:38:47.987390: step 126, loss 0.179158, acc 0.921875\n",
      "2020-06-12T11:38:49.483462: step 127, loss 0.168036, acc 0.90625\n",
      "2020-06-12T11:38:50.995347: step 128, loss 0.565477, acc 0.84375\n",
      "2020-06-12T11:38:52.479378: step 129, loss 0.256991, acc 0.921875\n",
      "2020-06-12T11:38:53.522588: step 130, loss 0.215339, acc 0.909091\n",
      "2020-06-12T11:38:55.077431: step 131, loss 0.0683647, acc 0.984375\n",
      "2020-06-12T11:38:56.594375: step 132, loss 0.360403, acc 0.90625\n",
      "2020-06-12T11:38:58.198087: step 133, loss 0.31832, acc 0.890625\n",
      "2020-06-12T11:38:59.735011: step 134, loss 0.106178, acc 0.96875\n",
      "2020-06-12T11:39:00.788161: step 135, loss 0.103607, acc 0.954545\n",
      "2020-06-12T11:39:02.322058: step 136, loss 0.17886, acc 0.953125\n",
      "2020-06-12T11:39:03.797116: step 137, loss 0.512701, acc 0.8125\n",
      "2020-06-12T11:39:05.324032: step 138, loss 0.354295, acc 0.875\n",
      "2020-06-12T11:39:06.805118: step 139, loss 0.229664, acc 0.90625\n",
      "2020-06-12T11:39:07.855264: step 140, loss 0.308061, acc 0.909091\n",
      "2020-06-12T11:39:09.376196: step 141, loss 0.189386, acc 0.9375\n",
      "2020-06-12T11:39:10.922062: step 142, loss 0.338621, acc 0.890625\n",
      "2020-06-12T11:39:12.434020: step 143, loss 0.231854, acc 0.9375\n",
      "2020-06-12T11:39:13.940991: step 144, loss 0.21148, acc 0.921875\n",
      "2020-06-12T11:39:14.982280: step 145, loss 0.103832, acc 0.954545\n",
      "2020-06-12T11:39:16.458259: step 146, loss 0.331773, acc 0.90625\n",
      "2020-06-12T11:39:18.001133: step 147, loss 0.385299, acc 0.890625\n",
      "2020-06-12T11:39:19.485166: step 148, loss 0.262854, acc 0.9375\n",
      "2020-06-12T11:39:20.990141: step 149, loss 0.0957103, acc 0.96875\n",
      "2020-06-12T11:39:21.996449: step 150, loss 0.250634, acc 0.931818\n",
      "2020-06-12T11:39:23.471547: step 151, loss 0.163407, acc 0.9375\n",
      "2020-06-12T11:39:24.977479: step 152, loss 0.276482, acc 0.921875\n",
      "2020-06-12T11:39:26.516365: step 153, loss 0.327437, acc 0.90625\n",
      "2020-06-12T11:39:28.046273: step 154, loss 0.326955, acc 0.890625\n",
      "2020-06-12T11:39:29.126458: step 155, loss 0.396707, acc 0.931818\n",
      "2020-06-12T11:39:30.620389: step 156, loss 0.167598, acc 0.953125\n",
      "2020-06-12T11:39:32.122375: step 157, loss 0.101484, acc 0.953125\n",
      "2020-06-12T11:39:33.612389: step 158, loss 0.217898, acc 0.9375\n",
      "2020-06-12T11:39:35.121354: step 159, loss 0.354905, acc 0.90625\n",
      "2020-06-12T11:39:36.158580: step 160, loss 0.363955, acc 0.886364\n",
      "2020-06-12T11:39:37.644607: step 161, loss 0.188717, acc 0.921875\n",
      "2020-06-12T11:39:39.153643: step 162, loss 0.162745, acc 0.9375\n",
      "2020-06-12T11:39:40.641593: step 163, loss 0.118392, acc 0.953125\n",
      "2020-06-12T11:39:42.212437: step 164, loss 0.129731, acc 0.9375\n",
      "2020-06-12T11:39:43.255603: step 165, loss 0.270055, acc 0.886364\n",
      "2020-06-12T11:39:44.797481: step 166, loss 0.234709, acc 0.921875\n",
      "2020-06-12T11:39:46.287497: step 167, loss 0.135285, acc 0.953125\n",
      "2020-06-12T11:39:47.789501: step 168, loss 0.0552378, acc 0.984375\n",
      "2020-06-12T11:39:49.248579: step 169, loss 0.308134, acc 0.875\n",
      "2020-06-12T11:39:50.388530: step 170, loss 0.186089, acc 0.909091\n",
      "2020-06-12T11:39:51.892509: step 171, loss 0.0847632, acc 0.953125\n",
      "2020-06-12T11:39:53.394534: step 172, loss 0.208501, acc 0.890625\n",
      "2020-06-12T11:39:54.898520: step 173, loss 0.0641152, acc 0.96875\n",
      "2020-06-12T11:39:56.384569: step 174, loss 0.122369, acc 0.953125\n",
      "2020-06-12T11:39:57.503505: step 175, loss 0.16168, acc 0.931818\n",
      "2020-06-12T11:39:59.021447: step 176, loss 0.171308, acc 0.921875\n",
      "2020-06-12T11:40:00.481543: step 177, loss 0.247977, acc 0.921875\n",
      "2020-06-12T11:40:02.030400: step 178, loss 0.139917, acc 0.9375\n",
      "2020-06-12T11:40:03.535375: step 179, loss 0.201434, acc 0.921875\n",
      "2020-06-12T11:40:04.581640: step 180, loss 0.0693024, acc 0.977273\n",
      "2020-06-12T11:40:06.056635: step 181, loss 0.123051, acc 0.90625\n",
      "2020-06-12T11:40:07.539670: step 182, loss 0.153472, acc 0.9375\n",
      "2020-06-12T11:40:09.017780: step 183, loss 0.210321, acc 0.90625\n",
      "2020-06-12T11:40:10.477813: step 184, loss 0.30511, acc 0.90625\n",
      "2020-06-12T11:40:11.500139: step 185, loss 0.147754, acc 0.909091\n",
      "2020-06-12T11:40:12.990096: step 186, loss 0.0810734, acc 0.96875\n",
      "2020-06-12T11:40:14.564884: step 187, loss 0.0775659, acc 0.96875\n",
      "2020-06-12T11:40:16.051956: step 188, loss 0.178474, acc 0.921875\n",
      "2020-06-12T11:40:17.578825: step 189, loss 0.0714169, acc 0.953125\n",
      "2020-06-12T11:40:18.583139: step 190, loss 0.171, acc 0.977273\n",
      "2020-06-12T11:40:20.055246: step 191, loss 0.0800334, acc 0.953125\n",
      "2020-06-12T11:40:21.552200: step 192, loss 0.135262, acc 0.984375\n",
      "2020-06-12T11:40:23.056249: step 193, loss 0.104453, acc 0.953125\n",
      "2020-06-12T11:40:24.575118: step 194, loss 0.0647198, acc 0.96875\n",
      "2020-06-12T11:40:25.604437: step 195, loss 0.128533, acc 0.954545\n",
      "2020-06-12T11:40:27.083410: step 196, loss 0.0821354, acc 0.96875\n",
      "2020-06-12T11:40:28.698093: step 197, loss 0.141931, acc 0.953125\n",
      "2020-06-12T11:40:30.294823: step 198, loss 0.174427, acc 0.9375\n",
      "2020-06-12T11:40:31.820742: step 199, loss 0.0799365, acc 0.984375\n",
      "2020-06-12T11:40:32.864950: step 200, loss 0.0748706, acc 0.977273\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:40:32.991611: step 200, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-200\n",
      "\n",
      "2020-06-12T11:40:34.975308: step 201, loss 0.215184, acc 0.921875\n",
      "2020-06-12T11:40:36.448369: step 202, loss 0.135855, acc 0.96875\n",
      "2020-06-12T11:40:37.921471: step 203, loss 0.205616, acc 0.953125\n",
      "2020-06-12T11:40:39.413440: step 204, loss 0.152019, acc 0.90625\n",
      "2020-06-12T11:40:40.432713: step 205, loss 0.107758, acc 0.977273\n",
      "2020-06-12T11:40:41.918740: step 206, loss 0.0790635, acc 0.953125\n",
      "2020-06-12T11:40:43.400777: step 207, loss 0.120051, acc 0.953125\n",
      "2020-06-12T11:40:44.962601: step 208, loss 0.142816, acc 0.953125\n",
      "2020-06-12T11:40:46.521432: step 209, loss 0.130517, acc 0.9375\n",
      "2020-06-12T11:40:47.584590: step 210, loss 0.0908806, acc 0.977273\n",
      "2020-06-12T11:40:49.152399: step 211, loss 0.1995, acc 0.953125\n",
      "2020-06-12T11:40:50.639422: step 212, loss 0.320369, acc 0.921875\n",
      "2020-06-12T11:40:52.162348: step 213, loss 0.161496, acc 0.9375\n",
      "2020-06-12T11:40:53.661340: step 214, loss 0.0829061, acc 0.96875\n",
      "2020-06-12T11:40:54.718514: step 215, loss 0.0241259, acc 1\n",
      "2020-06-12T11:40:56.156670: step 216, loss 0.0879736, acc 0.953125\n",
      "2020-06-12T11:40:57.665634: step 217, loss 0.148489, acc 0.96875\n",
      "2020-06-12T11:40:59.160636: step 218, loss 0.277738, acc 0.890625\n",
      "2020-06-12T11:41:00.653643: step 219, loss 0.0922537, acc 0.96875\n",
      "2020-06-12T11:41:01.750711: step 220, loss 0.254871, acc 0.954545\n",
      "2020-06-12T11:41:03.264663: step 221, loss 0.0946167, acc 0.953125\n",
      "2020-06-12T11:41:04.780609: step 222, loss 0.0851563, acc 0.96875\n",
      "2020-06-12T11:41:06.241701: step 223, loss 0.192454, acc 0.921875\n",
      "2020-06-12T11:41:07.736704: step 224, loss 0.0918271, acc 0.96875\n",
      "2020-06-12T11:41:08.778917: step 225, loss 0.0992268, acc 0.977273\n",
      "2020-06-12T11:41:10.238016: step 226, loss 0.064148, acc 0.96875\n",
      "2020-06-12T11:41:11.772953: step 227, loss 0.0794033, acc 0.96875\n",
      "2020-06-12T11:41:13.255020: step 228, loss 0.162411, acc 0.9375\n",
      "2020-06-12T11:41:14.741017: step 229, loss 0.133944, acc 0.9375\n",
      "2020-06-12T11:41:15.759314: step 230, loss 0.0656004, acc 0.954545\n",
      "2020-06-12T11:41:17.251261: step 231, loss 0.216464, acc 0.921875\n",
      "2020-06-12T11:41:18.816079: step 232, loss 0.029695, acc 1\n",
      "2020-06-12T11:41:20.274179: step 233, loss 0.0768036, acc 0.984375\n",
      "2020-06-12T11:41:21.841986: step 234, loss 0.0860902, acc 0.96875\n",
      "2020-06-12T11:41:22.853331: step 235, loss 0.0577514, acc 0.977273\n",
      "2020-06-12T11:41:24.343299: step 236, loss 0.0691713, acc 0.953125\n",
      "2020-06-12T11:41:25.851267: step 237, loss 0.130512, acc 0.953125\n",
      "2020-06-12T11:41:27.331310: step 238, loss 0.0747862, acc 0.96875\n",
      "2020-06-12T11:41:28.837283: step 239, loss 0.0678665, acc 0.984375\n",
      "2020-06-12T11:41:29.861544: step 240, loss 0.16312, acc 0.954545\n",
      "2020-06-12T11:41:31.315656: step 241, loss 0.144832, acc 0.9375\n",
      "2020-06-12T11:41:32.815644: step 242, loss 0.098397, acc 0.96875\n",
      "2020-06-12T11:41:34.350611: step 243, loss 0.0126233, acc 1\n",
      "2020-06-12T11:41:35.860503: step 244, loss 0.1817, acc 0.96875\n",
      "2020-06-12T11:41:36.897729: step 245, loss 0.0753532, acc 0.954545\n",
      "2020-06-12T11:41:38.384753: step 246, loss 0.0611326, acc 0.984375\n",
      "2020-06-12T11:41:39.891773: step 247, loss 0.118325, acc 0.953125\n",
      "2020-06-12T11:41:41.383733: step 248, loss 0.0768951, acc 0.96875\n",
      "2020-06-12T11:41:42.892697: step 249, loss 0.0768997, acc 0.96875\n",
      "2020-06-12T11:41:43.925935: step 250, loss 0.191492, acc 0.909091\n",
      "2020-06-12T11:41:45.423929: step 251, loss 0.0482721, acc 0.96875\n",
      "2020-06-12T11:41:46.879039: step 252, loss 0.07444, acc 0.953125\n",
      "2020-06-12T11:41:48.347114: step 253, loss 0.0892241, acc 0.96875\n",
      "2020-06-12T11:41:49.910932: step 254, loss 0.10775, acc 0.953125\n",
      "2020-06-12T11:41:51.060857: step 255, loss 0.0793161, acc 0.954545\n",
      "2020-06-12T11:41:52.620685: step 256, loss 0.0449093, acc 0.984375\n",
      "2020-06-12T11:41:54.096740: step 257, loss 0.0859171, acc 0.96875\n",
      "2020-06-12T11:41:55.603709: step 258, loss 0.216401, acc 0.9375\n",
      "2020-06-12T11:41:57.084750: step 259, loss 0.0772677, acc 0.953125\n",
      "2020-06-12T11:41:58.112002: step 260, loss 0.169157, acc 0.954545\n",
      "2020-06-12T11:41:59.628945: step 261, loss 0.0636162, acc 0.984375\n",
      "2020-06-12T11:42:01.118013: step 262, loss 0.154026, acc 0.9375\n",
      "2020-06-12T11:42:02.637901: step 263, loss 0.138596, acc 0.9375\n",
      "2020-06-12T11:42:04.083036: step 264, loss 0.0851894, acc 0.984375\n",
      "2020-06-12T11:42:05.125250: step 265, loss 0.108695, acc 0.954545\n",
      "2020-06-12T11:42:06.702103: step 266, loss 0.0625154, acc 0.96875\n",
      "2020-06-12T11:42:08.185068: step 267, loss 0.0773713, acc 0.96875\n",
      "2020-06-12T11:42:09.710987: step 268, loss 0.110495, acc 0.9375\n",
      "2020-06-12T11:42:11.205990: step 269, loss 0.0564472, acc 0.96875\n",
      "2020-06-12T11:42:12.225265: step 270, loss 0.033985, acc 1\n",
      "2020-06-12T11:42:13.722334: step 271, loss 0.0573918, acc 0.953125\n",
      "2020-06-12T11:42:15.179438: step 272, loss 0.0569262, acc 0.96875\n",
      "2020-06-12T11:42:16.702293: step 273, loss 0.130937, acc 0.9375\n",
      "2020-06-12T11:42:18.163462: step 274, loss 0.0368957, acc 0.984375\n",
      "2020-06-12T11:42:19.209587: step 275, loss 0.0461054, acc 0.977273\n",
      "2020-06-12T11:42:20.704591: step 276, loss 0.0481319, acc 0.984375\n",
      "2020-06-12T11:42:22.258436: step 277, loss 0.0977978, acc 0.953125\n",
      "2020-06-12T11:42:23.731496: step 278, loss 0.0254452, acc 0.984375\n",
      "2020-06-12T11:42:25.253452: step 279, loss 0.0137486, acc 1\n",
      "2020-06-12T11:42:26.294713: step 280, loss 0.0788262, acc 0.954545\n",
      "2020-06-12T11:42:27.771764: step 281, loss 0.0237685, acc 1\n",
      "2020-06-12T11:42:29.270686: step 282, loss 0.0738136, acc 0.96875\n",
      "2020-06-12T11:42:30.744743: step 283, loss 0.0333611, acc 0.984375\n",
      "2020-06-12T11:42:32.253708: step 284, loss 0.020957, acc 1\n",
      "2020-06-12T11:42:33.268993: step 285, loss 0.0235668, acc 1\n",
      "2020-06-12T11:42:34.762001: step 286, loss 0.0513199, acc 0.96875\n",
      "2020-06-12T11:42:36.249025: step 287, loss 0.0502611, acc 0.984375\n",
      "2020-06-12T11:42:37.782958: step 288, loss 0.0512364, acc 0.96875\n",
      "2020-06-12T11:42:39.324801: step 289, loss 0.0341968, acc 0.984375\n",
      "2020-06-12T11:42:40.349062: step 290, loss 0.0852884, acc 0.977273\n",
      "2020-06-12T11:42:41.880039: step 291, loss 0.0136503, acc 1\n",
      "2020-06-12T11:42:43.371978: step 292, loss 0.0473189, acc 0.984375\n",
      "2020-06-12T11:42:44.851065: step 293, loss 0.124237, acc 0.96875\n",
      "2020-06-12T11:42:46.363977: step 294, loss 0.091098, acc 0.96875\n",
      "2020-06-12T11:42:47.376272: step 295, loss 0.0355033, acc 1\n",
      "2020-06-12T11:42:48.859306: step 296, loss 0.0294608, acc 0.984375\n",
      "2020-06-12T11:42:50.353353: step 297, loss 0.0215285, acc 1\n",
      "2020-06-12T11:42:51.832356: step 298, loss 0.0500299, acc 0.96875\n",
      "2020-06-12T11:42:53.382211: step 299, loss 0.112494, acc 0.921875\n",
      "2020-06-12T11:42:54.447363: step 300, loss 0.0263004, acc 0.977273\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:42:54.570035: step 300, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-300\n",
      "\n",
      "2020-06-12T11:42:56.509849: step 301, loss 0.0207033, acc 0.984375\n",
      "2020-06-12T11:42:58.015820: step 302, loss 0.0261734, acc 1\n",
      "2020-06-12T11:42:59.504840: step 303, loss 0.0977121, acc 0.96875\n",
      "2020-06-12T11:43:00.996850: step 304, loss 0.0573994, acc 0.984375\n",
      "2020-06-12T11:43:02.026097: step 305, loss 0.0616428, acc 0.977273\n",
      "2020-06-12T11:43:03.535063: step 306, loss 0.0831768, acc 0.984375\n",
      "2020-06-12T11:43:05.014108: step 307, loss 0.02688, acc 0.984375\n",
      "2020-06-12T11:43:06.485187: step 308, loss 0.0824259, acc 0.984375\n",
      "2020-06-12T11:43:07.987158: step 309, loss 0.044698, acc 0.984375\n",
      "2020-06-12T11:43:09.042338: step 310, loss 0.0624701, acc 0.977273\n",
      "2020-06-12T11:43:10.610145: step 311, loss 0.050065, acc 0.984375\n",
      "2020-06-12T11:43:12.070239: step 312, loss 0.00929267, acc 1\n",
      "2020-06-12T11:43:13.617105: step 313, loss 0.0105658, acc 1\n",
      "2020-06-12T11:43:15.107120: step 314, loss 0.0770236, acc 0.96875\n",
      "2020-06-12T11:43:16.107444: step 315, loss 0.106852, acc 0.954545\n",
      "2020-06-12T11:43:17.610426: step 316, loss 0.130676, acc 0.953125\n",
      "2020-06-12T11:43:19.095456: step 317, loss 0.078075, acc 0.984375\n",
      "2020-06-12T11:43:20.603424: step 318, loss 0.0182123, acc 1\n",
      "2020-06-12T11:43:22.070571: step 319, loss 0.0886618, acc 0.96875\n",
      "2020-06-12T11:43:23.117769: step 320, loss 0.0703456, acc 0.977273\n",
      "2020-06-12T11:43:24.580813: step 321, loss 0.0322226, acc 0.984375\n",
      "2020-06-12T11:43:26.114687: step 322, loss 0.0261844, acc 0.984375\n",
      "2020-06-12T11:43:27.632626: step 323, loss 0.0429988, acc 0.984375\n",
      "2020-06-12T11:43:29.148574: step 324, loss 0.0323639, acc 0.984375\n",
      "2020-06-12T11:43:30.195773: step 325, loss 0.0119701, acc 1\n",
      "2020-06-12T11:43:31.671827: step 326, loss 0.0995762, acc 0.953125\n",
      "2020-06-12T11:43:33.185777: step 327, loss 0.00658892, acc 1\n",
      "2020-06-12T11:43:34.640886: step 328, loss 0.131645, acc 0.953125\n",
      "2020-06-12T11:43:36.125917: step 329, loss 0.0576213, acc 0.984375\n",
      "2020-06-12T11:43:37.140204: step 330, loss 0.0513159, acc 0.977273\n",
      "2020-06-12T11:43:38.641189: step 331, loss 0.038373, acc 0.984375\n",
      "2020-06-12T11:43:40.138229: step 332, loss 0.055038, acc 0.96875\n",
      "2020-06-12T11:43:41.641169: step 333, loss 0.0304997, acc 0.984375\n",
      "2020-06-12T11:43:43.195012: step 334, loss 0.0373257, acc 1\n",
      "2020-06-12T11:43:44.246273: step 335, loss 0.0223889, acc 1\n",
      "2020-06-12T11:43:45.764145: step 336, loss 0.0204507, acc 1\n",
      "2020-06-12T11:43:47.261142: step 337, loss 0.0511719, acc 0.984375\n",
      "2020-06-12T11:43:48.745173: step 338, loss 0.133943, acc 0.96875\n",
      "2020-06-12T11:43:50.251217: step 339, loss 0.065123, acc 0.953125\n",
      "2020-06-12T11:43:51.369198: step 340, loss 0.0362372, acc 0.977273\n",
      "2020-06-12T11:43:52.857177: step 341, loss 0.167521, acc 0.953125\n",
      "2020-06-12T11:43:54.324325: step 342, loss 0.0597336, acc 0.96875\n",
      "2020-06-12T11:43:55.802302: step 343, loss 0.0181399, acc 1\n",
      "2020-06-12T11:43:57.346215: step 344, loss 0.0281542, acc 0.984375\n",
      "2020-06-12T11:43:58.437256: step 345, loss 0.0540205, acc 0.954545\n",
      "2020-06-12T11:43:59.951251: step 346, loss 0.102117, acc 0.953125\n",
      "2020-06-12T11:44:01.493085: step 347, loss 0.0330522, acc 1\n",
      "2020-06-12T11:44:03.007037: step 348, loss 0.0491972, acc 0.96875\n",
      "2020-06-12T11:44:04.516001: step 349, loss 0.118822, acc 0.96875\n",
      "2020-06-12T11:44:05.533366: step 350, loss 0.0697253, acc 0.977273\n",
      "2020-06-12T11:44:07.033271: step 351, loss 0.0615792, acc 0.984375\n",
      "2020-06-12T11:44:08.518300: step 352, loss 0.0110974, acc 1\n",
      "2020-06-12T11:44:10.028262: step 353, loss 0.163129, acc 0.921875\n",
      "2020-06-12T11:44:11.526328: step 354, loss 0.120821, acc 0.984375\n",
      "2020-06-12T11:44:12.541541: step 355, loss 0.00305033, acc 1\n",
      "2020-06-12T11:44:14.114337: step 356, loss 0.110478, acc 0.96875\n",
      "2020-06-12T11:44:15.609383: step 357, loss 0.0144306, acc 1\n",
      "2020-06-12T11:44:17.167174: step 358, loss 0.0466907, acc 0.984375\n",
      "2020-06-12T11:44:18.661220: step 359, loss 0.0430883, acc 0.984375\n",
      "2020-06-12T11:44:19.709374: step 360, loss 0.0448561, acc 0.977273\n",
      "2020-06-12T11:44:21.204378: step 361, loss 0.117451, acc 0.984375\n",
      "2020-06-12T11:44:22.688409: step 362, loss 0.0439682, acc 0.984375\n",
      "2020-06-12T11:44:24.186405: step 363, loss 0.0429623, acc 0.984375\n",
      "2020-06-12T11:44:25.655476: step 364, loss 0.00706896, acc 1\n",
      "2020-06-12T11:44:26.699733: step 365, loss 0.0211778, acc 1\n",
      "2020-06-12T11:44:28.187706: step 366, loss 0.0651113, acc 0.984375\n",
      "2020-06-12T11:44:29.756511: step 367, loss 0.0695717, acc 0.96875\n",
      "2020-06-12T11:44:31.242536: step 368, loss 0.0656217, acc 0.96875\n",
      "2020-06-12T11:44:32.746516: step 369, loss 0.0381569, acc 0.984375\n",
      "2020-06-12T11:44:33.803746: step 370, loss 0.0731145, acc 0.977273\n",
      "2020-06-12T11:44:35.295698: step 371, loss 0.016204, acc 1\n",
      "2020-06-12T11:44:36.767761: step 372, loss 0.0705078, acc 0.96875\n",
      "2020-06-12T11:44:38.239827: step 373, loss 0.152086, acc 0.953125\n",
      "2020-06-12T11:44:39.739865: step 374, loss 0.00320526, acc 1\n",
      "2020-06-12T11:44:40.774050: step 375, loss 0.0510281, acc 0.977273\n",
      "2020-06-12T11:44:42.271046: step 376, loss 0.0535471, acc 0.984375\n",
      "2020-06-12T11:44:43.775025: step 377, loss 0.0551769, acc 0.984375\n",
      "2020-06-12T11:44:45.267035: step 378, loss 0.0241482, acc 1\n",
      "2020-06-12T11:44:46.848805: step 379, loss 0.085185, acc 0.96875\n",
      "2020-06-12T11:44:47.878053: step 380, loss 0.101938, acc 0.954545\n",
      "2020-06-12T11:44:49.412950: step 381, loss 0.134295, acc 0.953125\n",
      "2020-06-12T11:44:50.879094: step 382, loss 0.0369341, acc 0.984375\n",
      "2020-06-12T11:44:52.382010: step 383, loss 0.0736773, acc 0.984375\n",
      "2020-06-12T11:44:53.888995: step 384, loss 0.00651212, acc 1\n",
      "2020-06-12T11:44:54.915236: step 385, loss 0.0757176, acc 0.977273\n",
      "2020-06-12T11:44:56.400336: step 386, loss 0.0465717, acc 0.984375\n",
      "2020-06-12T11:44:57.888313: step 387, loss 0.00821372, acc 1\n",
      "2020-06-12T11:44:59.350376: step 388, loss 0.0232257, acc 0.984375\n",
      "2020-06-12T11:45:00.830420: step 389, loss 0.0214936, acc 1\n",
      "2020-06-12T11:45:01.898564: step 390, loss 0.0351152, acc 0.977273\n",
      "2020-06-12T11:45:03.423485: step 391, loss 0.0165293, acc 1\n",
      "2020-06-12T11:45:04.932450: step 392, loss 0.0450728, acc 0.96875\n",
      "2020-06-12T11:45:06.442412: step 393, loss 0.0614466, acc 0.984375\n",
      "2020-06-12T11:45:07.895598: step 394, loss 0.0262398, acc 0.984375\n",
      "2020-06-12T11:45:08.919788: step 395, loss 0.021308, acc 1\n",
      "2020-06-12T11:45:10.399830: step 396, loss 0.0525845, acc 0.96875\n",
      "2020-06-12T11:45:11.880869: step 397, loss 0.024144, acc 1\n",
      "2020-06-12T11:45:13.395818: step 398, loss 0.0563054, acc 0.96875\n",
      "2020-06-12T11:45:14.854959: step 399, loss 0.014228, acc 1\n",
      "2020-06-12T11:45:15.862225: step 400, loss 0.0225062, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:45:15.985893: step 400, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-400\n",
      "\n",
      "2020-06-12T11:45:17.866864: step 401, loss 0.0272577, acc 0.984375\n",
      "2020-06-12T11:45:19.390790: step 402, loss 0.0116088, acc 1\n",
      "2020-06-12T11:45:20.918704: step 403, loss 0.0330449, acc 0.984375\n",
      "2020-06-12T11:45:22.413707: step 404, loss 0.0289157, acc 0.984375\n",
      "2020-06-12T11:45:23.425076: step 405, loss 0.0382746, acc 0.977273\n",
      "2020-06-12T11:45:24.910032: step 406, loss 0.00827805, acc 1\n",
      "2020-06-12T11:45:26.425051: step 407, loss 0.0218901, acc 1\n",
      "2020-06-12T11:45:27.899039: step 408, loss 0.0721037, acc 0.96875\n",
      "2020-06-12T11:45:29.380079: step 409, loss 0.0455012, acc 0.984375\n",
      "2020-06-12T11:45:30.400350: step 410, loss 0.0531466, acc 0.954545\n",
      "2020-06-12T11:45:31.892360: step 411, loss 0.0110315, acc 1\n",
      "2020-06-12T11:45:33.435236: step 412, loss 0.0151102, acc 1\n",
      "2020-06-12T11:45:34.968135: step 413, loss 0.0289055, acc 0.984375\n",
      "2020-06-12T11:45:36.449175: step 414, loss 0.102321, acc 0.953125\n",
      "2020-06-12T11:45:37.522351: step 415, loss 0.0165815, acc 1\n",
      "2020-06-12T11:45:39.005342: step 416, loss 0.026838, acc 1\n",
      "2020-06-12T11:45:40.478451: step 417, loss 0.0199819, acc 1\n",
      "2020-06-12T11:45:41.957447: step 418, loss 0.0487397, acc 0.984375\n",
      "2020-06-12T11:45:43.465457: step 419, loss 0.00170473, acc 1\n",
      "2020-06-12T11:45:44.486683: step 420, loss 0.0228505, acc 1\n",
      "2020-06-12T11:45:45.973706: step 421, loss 0.00581152, acc 1\n",
      "2020-06-12T11:45:47.462726: step 422, loss 0.00755954, acc 1\n",
      "2020-06-12T11:45:48.950747: step 423, loss 0.0078001, acc 1\n",
      "2020-06-12T11:45:50.519626: step 424, loss 0.0121964, acc 1\n",
      "2020-06-12T11:45:51.687500: step 425, loss 0.118503, acc 0.954545\n",
      "2020-06-12T11:45:53.226314: step 426, loss 0.0805357, acc 0.953125\n",
      "2020-06-12T11:45:54.724309: step 427, loss 0.0286954, acc 0.984375\n",
      "2020-06-12T11:45:56.185400: step 428, loss 0.0169615, acc 1\n",
      "2020-06-12T11:45:57.721296: step 429, loss 0.078691, acc 0.96875\n",
      "2020-06-12T11:45:58.762510: step 430, loss 0.0805746, acc 0.954545\n",
      "2020-06-12T11:46:00.270479: step 431, loss 0.030684, acc 0.984375\n",
      "2020-06-12T11:46:01.784429: step 432, loss 0.0579618, acc 0.984375\n",
      "2020-06-12T11:46:03.327305: step 433, loss 0.066553, acc 0.953125\n",
      "2020-06-12T11:46:04.835273: step 434, loss 0.0463992, acc 0.984375\n",
      "2020-06-12T11:46:05.937326: step 435, loss 0.130292, acc 0.931818\n",
      "2020-06-12T11:46:07.444368: step 436, loss 0.078821, acc 0.96875\n",
      "2020-06-12T11:46:08.995149: step 437, loss 0.0245817, acc 1\n",
      "2020-06-12T11:46:10.501177: step 438, loss 0.0109429, acc 1\n",
      "2020-06-12T11:46:11.977176: step 439, loss 0.0074526, acc 1\n",
      "2020-06-12T11:46:13.029361: step 440, loss 0.121567, acc 0.931818\n",
      "2020-06-12T11:46:14.503461: step 441, loss 0.064306, acc 0.984375\n",
      "2020-06-12T11:46:15.984458: step 442, loss 0.0216415, acc 1\n",
      "2020-06-12T11:46:17.466548: step 443, loss 0.0388279, acc 0.984375\n",
      "2020-06-12T11:46:18.913627: step 444, loss 0.00613164, acc 1\n",
      "2020-06-12T11:46:19.956916: step 445, loss 0.0118937, acc 1\n",
      "2020-06-12T11:46:21.468795: step 446, loss 0.0072456, acc 1\n",
      "2020-06-12T11:46:23.014662: step 447, loss 0.0635258, acc 0.96875\n",
      "2020-06-12T11:46:24.516644: step 448, loss 0.00804804, acc 1\n",
      "2020-06-12T11:46:26.037579: step 449, loss 0.00910794, acc 1\n",
      "2020-06-12T11:46:27.044942: step 450, loss 0.139175, acc 0.954545\n",
      "2020-06-12T11:46:28.517000: step 451, loss 0.00666314, acc 1\n",
      "2020-06-12T11:46:30.006965: step 452, loss 0.0178411, acc 1\n",
      "2020-06-12T11:46:31.471122: step 453, loss 0.00386545, acc 1\n",
      "2020-06-12T11:46:32.960112: step 454, loss 0.0637338, acc 0.984375\n",
      "2020-06-12T11:46:33.976429: step 455, loss 0.00559324, acc 1\n",
      "2020-06-12T11:46:35.483393: step 456, loss 0.00794596, acc 1\n",
      "2020-06-12T11:46:36.991333: step 457, loss 0.0270304, acc 0.984375\n",
      "2020-06-12T11:46:38.533166: step 458, loss 0.0108171, acc 1\n",
      "2020-06-12T11:46:40.095001: step 459, loss 0.0200564, acc 1\n",
      "2020-06-12T11:46:41.179090: step 460, loss 0.0143849, acc 1\n",
      "2020-06-12T11:46:42.680076: step 461, loss 0.0539638, acc 0.96875\n",
      "2020-06-12T11:46:44.149149: step 462, loss 0.117454, acc 0.953125\n",
      "2020-06-12T11:46:45.631185: step 463, loss 0.00489449, acc 1\n",
      "2020-06-12T11:46:47.122197: step 464, loss 0.0256737, acc 0.984375\n",
      "2020-06-12T11:46:48.139549: step 465, loss 0.0565441, acc 0.977273\n",
      "2020-06-12T11:46:49.639468: step 466, loss 0.00394626, acc 1\n",
      "2020-06-12T11:46:51.107583: step 467, loss 0.0146001, acc 1\n",
      "2020-06-12T11:46:52.617503: step 468, loss 0.0177691, acc 0.984375\n",
      "2020-06-12T11:46:54.167359: step 469, loss 0.0477261, acc 0.96875\n",
      "2020-06-12T11:46:55.180650: step 470, loss 0.0275093, acc 1\n",
      "2020-06-12T11:46:56.704575: step 471, loss 0.0110066, acc 1\n",
      "2020-06-12T11:46:58.198622: step 472, loss 0.0156276, acc 1\n",
      "2020-06-12T11:46:59.712581: step 473, loss 0.00112607, acc 1\n",
      "2020-06-12T11:47:01.225528: step 474, loss 0.0238953, acc 0.984375\n",
      "2020-06-12T11:47:02.251743: step 475, loss 0.105924, acc 0.977273\n",
      "2020-06-12T11:47:03.747743: step 476, loss 0.0804183, acc 0.96875\n",
      "2020-06-12T11:47:05.246735: step 477, loss 0.0361378, acc 0.984375\n",
      "2020-06-12T11:47:06.747719: step 478, loss 0.0407204, acc 0.984375\n",
      "2020-06-12T11:47:08.207816: step 479, loss 0.0439459, acc 0.984375\n",
      "2020-06-12T11:47:09.294910: step 480, loss 0.105857, acc 0.977273\n",
      "2020-06-12T11:47:10.816840: step 481, loss 0.0228329, acc 1\n",
      "2020-06-12T11:47:12.305858: step 482, loss 0.0230013, acc 0.984375\n",
      "2020-06-12T11:47:13.831777: step 483, loss 0.0140136, acc 1\n",
      "2020-06-12T11:47:15.319849: step 484, loss 0.0324251, acc 0.984375\n",
      "2020-06-12T11:47:16.347052: step 485, loss 0.0368238, acc 0.977273\n",
      "2020-06-12T11:47:17.809184: step 486, loss 0.00853471, acc 1\n",
      "2020-06-12T11:47:19.277216: step 487, loss 0.00386216, acc 1\n",
      "2020-06-12T11:47:20.725388: step 488, loss 0.0157093, acc 1\n",
      "2020-06-12T11:47:22.194417: step 489, loss 0.0223262, acc 1\n",
      "2020-06-12T11:47:23.263557: step 490, loss 0.00949515, acc 1\n",
      "2020-06-12T11:47:24.747589: step 491, loss 0.0587791, acc 0.984375\n",
      "2020-06-12T11:47:26.298443: step 492, loss 0.0566768, acc 0.96875\n",
      "2020-06-12T11:47:27.765520: step 493, loss 0.00149113, acc 1\n",
      "2020-06-12T11:47:29.308394: step 494, loss 0.0101236, acc 1\n",
      "2020-06-12T11:47:30.333651: step 495, loss 0.0910916, acc 0.977273\n",
      "2020-06-12T11:47:31.816685: step 496, loss 0.0794912, acc 0.984375\n",
      "2020-06-12T11:47:33.326694: step 497, loss 0.065707, acc 0.984375\n",
      "2020-06-12T11:47:34.816706: step 498, loss 0.0515375, acc 0.984375\n",
      "2020-06-12T11:47:36.319646: step 499, loss 0.0176197, acc 0.984375\n",
      "2020-06-12T11:47:37.339918: step 500, loss 0.00497986, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:47:37.459597: step 500, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-500\n",
      "\n",
      "2020-06-12T11:47:39.395422: step 501, loss 0.048656, acc 0.984375\n",
      "2020-06-12T11:47:40.907379: step 502, loss 0.0181409, acc 1\n",
      "2020-06-12T11:47:42.453246: step 503, loss 0.00385883, acc 1\n",
      "2020-06-12T11:47:43.954231: step 504, loss 0.1459, acc 0.953125\n",
      "2020-06-12T11:47:45.019384: step 505, loss 0.0103445, acc 1\n",
      "2020-06-12T11:47:46.538322: step 506, loss 0.0322692, acc 0.984375\n",
      "2020-06-12T11:47:48.014376: step 507, loss 0.00562975, acc 1\n",
      "2020-06-12T11:47:49.530321: step 508, loss 0.114836, acc 0.953125\n",
      "2020-06-12T11:47:50.997399: step 509, loss 0.00508561, acc 1\n",
      "2020-06-12T11:47:52.069531: step 510, loss 0.0228722, acc 1\n",
      "2020-06-12T11:47:53.558548: step 511, loss 0.00582965, acc 1\n",
      "2020-06-12T11:47:55.026623: step 512, loss 0.0583702, acc 0.984375\n",
      "2020-06-12T11:47:56.527652: step 513, loss 0.0316242, acc 1\n",
      "2020-06-12T11:47:58.083452: step 514, loss 0.0275204, acc 0.984375\n",
      "2020-06-12T11:47:59.119678: step 515, loss 0.00249802, acc 1\n",
      "2020-06-12T11:48:00.607700: step 516, loss 0.0103517, acc 1\n",
      "2020-06-12T11:48:02.108686: step 517, loss 0.00526269, acc 1\n",
      "2020-06-12T11:48:03.624680: step 518, loss 0.00767892, acc 1\n",
      "2020-06-12T11:48:05.158531: step 519, loss 0.0298565, acc 0.984375\n",
      "2020-06-12T11:48:06.310452: step 520, loss 0.0949407, acc 0.977273\n",
      "2020-06-12T11:48:07.834377: step 521, loss 0.10612, acc 0.984375\n",
      "2020-06-12T11:48:09.324393: step 522, loss 0.0294737, acc 0.96875\n",
      "2020-06-12T11:48:10.829439: step 523, loss 0.0377552, acc 0.96875\n",
      "2020-06-12T11:48:12.312404: step 524, loss 0.00887931, acc 1\n",
      "2020-06-12T11:48:13.410467: step 525, loss 0.0240581, acc 1\n",
      "2020-06-12T11:48:14.930401: step 526, loss 0.00799739, acc 1\n",
      "2020-06-12T11:48:16.431460: step 527, loss 0.00515938, acc 1\n",
      "2020-06-12T11:48:17.969277: step 528, loss 0.0451758, acc 0.984375\n",
      "2020-06-12T11:48:19.479239: step 529, loss 0.00348976, acc 1\n",
      "2020-06-12T11:48:20.480561: step 530, loss 0.0692049, acc 0.954545\n",
      "2020-06-12T11:48:21.975563: step 531, loss 0.0109623, acc 1\n",
      "2020-06-12T11:48:23.483531: step 532, loss 0.0248549, acc 0.984375\n",
      "2020-06-12T11:48:24.959626: step 533, loss 0.0381842, acc 0.984375\n",
      "2020-06-12T11:48:26.467594: step 534, loss 0.0259489, acc 0.984375\n",
      "2020-06-12T11:48:27.488821: step 535, loss 0.0112285, acc 1\n",
      "2020-06-12T11:48:28.986815: step 536, loss 0.0160392, acc 1\n",
      "2020-06-12T11:48:30.559651: step 537, loss 0.040193, acc 0.984375\n",
      "2020-06-12T11:48:32.068576: step 538, loss 0.00188664, acc 1\n",
      "2020-06-12T11:48:33.632464: step 539, loss 0.00192997, acc 1\n",
      "2020-06-12T11:48:34.655656: step 540, loss 0.0130225, acc 1\n",
      "2020-06-12T11:48:36.150661: step 541, loss 0.00156751, acc 1\n",
      "2020-06-12T11:48:37.621726: step 542, loss 0.0156759, acc 1\n",
      "2020-06-12T11:48:39.086807: step 543, loss 0.0376535, acc 0.984375\n",
      "2020-06-12T11:48:40.637660: step 544, loss 0.0258817, acc 0.984375\n",
      "2020-06-12T11:48:41.842440: step 545, loss 0.0115409, acc 1\n",
      "2020-06-12T11:48:43.431192: step 546, loss 0.0708306, acc 0.96875\n",
      "2020-06-12T11:48:44.979052: step 547, loss 0.0237184, acc 1\n",
      "2020-06-12T11:48:46.588749: step 548, loss 0.16242, acc 0.921875\n",
      "2020-06-12T11:48:48.099708: step 549, loss 0.0141223, acc 1\n",
      "2020-06-12T11:48:49.135937: step 550, loss 0.0409318, acc 0.977273\n",
      "2020-06-12T11:48:50.655873: step 551, loss 0.0340201, acc 0.984375\n",
      "2020-06-12T11:48:52.239640: step 552, loss 0.00263098, acc 1\n",
      "2020-06-12T11:48:53.859308: step 553, loss 0.00429819, acc 1\n",
      "2020-06-12T11:48:55.383232: step 554, loss 0.00678363, acc 1\n",
      "2020-06-12T11:48:56.512215: step 555, loss 0.0044174, acc 1\n",
      "2020-06-12T11:48:58.069051: step 556, loss 0.015303, acc 1\n",
      "2020-06-12T11:48:59.649823: step 557, loss 0.0120019, acc 0.984375\n",
      "2020-06-12T11:49:01.251541: step 558, loss 0.00320215, acc 1\n",
      "2020-06-12T11:49:02.823380: step 559, loss 0.00200196, acc 1\n",
      "2020-06-12T11:49:03.869541: step 560, loss 0.0189196, acc 1\n",
      "2020-06-12T11:49:05.352617: step 561, loss 0.120009, acc 0.984375\n",
      "2020-06-12T11:49:06.885477: step 562, loss 0.00503296, acc 1\n",
      "2020-06-12T11:49:08.382472: step 563, loss 0.0198315, acc 0.984375\n",
      "2020-06-12T11:49:09.909390: step 564, loss 0.00941271, acc 1\n",
      "2020-06-12T11:49:10.927731: step 565, loss 0.0287138, acc 0.977273\n",
      "2020-06-12T11:49:12.403721: step 566, loss 0.00391, acc 1\n",
      "2020-06-12T11:49:13.904707: step 567, loss 0.0318775, acc 0.984375\n",
      "2020-06-12T11:49:15.327901: step 568, loss 0.00935999, acc 1\n",
      "2020-06-12T11:49:16.853821: step 569, loss 0.00813891, acc 1\n",
      "2020-06-12T11:49:17.929943: step 570, loss 0.0159599, acc 1\n",
      "2020-06-12T11:49:19.459879: step 571, loss 0.0168998, acc 1\n",
      "2020-06-12T11:49:20.927928: step 572, loss 0.0772824, acc 0.953125\n",
      "2020-06-12T11:49:22.422930: step 573, loss 0.0258631, acc 0.984375\n",
      "2020-06-12T11:49:23.934957: step 574, loss 0.0605358, acc 0.953125\n",
      "2020-06-12T11:49:24.959148: step 575, loss 0.0698826, acc 0.977273\n",
      "2020-06-12T11:49:26.436198: step 576, loss 0.0811043, acc 0.984375\n",
      "2020-06-12T11:49:27.928209: step 577, loss 0.00312425, acc 1\n",
      "2020-06-12T11:49:29.399276: step 578, loss 0.0284193, acc 0.984375\n",
      "2020-06-12T11:49:30.903327: step 579, loss 0.021737, acc 0.984375\n",
      "2020-06-12T11:49:31.927515: step 580, loss 0.0125226, acc 1\n",
      "2020-06-12T11:49:33.460415: step 581, loss 0.0396907, acc 0.984375\n",
      "2020-06-12T11:49:35.031216: step 582, loss 0.0783593, acc 0.96875\n",
      "2020-06-12T11:49:36.549155: step 583, loss 0.0072432, acc 1\n",
      "2020-06-12T11:49:38.057166: step 584, loss 0.0543743, acc 0.953125\n",
      "2020-06-12T11:49:39.079389: step 585, loss 0.0341252, acc 1\n",
      "2020-06-12T11:49:40.699058: step 586, loss 0.0200344, acc 1\n",
      "2020-06-12T11:49:42.212015: step 587, loss 0.00323686, acc 1\n",
      "2020-06-12T11:49:43.730952: step 588, loss 0.0103353, acc 1\n",
      "2020-06-12T11:49:45.218974: step 589, loss 0.00552061, acc 1\n",
      "2020-06-12T11:49:46.266173: step 590, loss 0.047623, acc 0.977273\n",
      "2020-06-12T11:49:47.758255: step 591, loss 0.0484302, acc 0.984375\n",
      "2020-06-12T11:49:49.251192: step 592, loss 0.00231711, acc 1\n",
      "2020-06-12T11:49:50.796062: step 593, loss 0.00485586, acc 1\n",
      "2020-06-12T11:49:52.333949: step 594, loss 0.00709563, acc 1\n",
      "2020-06-12T11:49:53.546706: step 595, loss 0.0341438, acc 1\n",
      "2020-06-12T11:49:55.032732: step 596, loss 0.0804956, acc 0.96875\n",
      "2020-06-12T11:49:56.542695: step 597, loss 0.0298299, acc 0.984375\n",
      "2020-06-12T11:49:58.063627: step 598, loss 0.0153624, acc 1\n",
      "2020-06-12T11:49:59.557633: step 599, loss 0.0209925, acc 0.984375\n",
      "2020-06-12T11:50:00.585883: step 600, loss 0.0129521, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:50:00.708555: step 600, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-600\n",
      "\n",
      "2020-06-12T11:50:02.632410: step 601, loss 0.0787191, acc 0.984375\n",
      "2020-06-12T11:50:04.106521: step 602, loss 0.0319477, acc 0.984375\n",
      "2020-06-12T11:50:05.606457: step 603, loss 0.0155881, acc 1\n",
      "2020-06-12T11:50:07.197205: step 604, loss 0.0072733, acc 1\n",
      "2020-06-12T11:50:08.224457: step 605, loss 0.0378782, acc 1\n",
      "2020-06-12T11:50:09.734419: step 606, loss 0.0357389, acc 0.984375\n",
      "2020-06-12T11:50:11.206525: step 607, loss 0.00528947, acc 1\n",
      "2020-06-12T11:50:12.675556: step 608, loss 0.00806119, acc 1\n",
      "2020-06-12T11:50:14.158590: step 609, loss 0.0100886, acc 1\n",
      "2020-06-12T11:50:15.180856: step 610, loss 0.0156653, acc 1\n",
      "2020-06-12T11:50:16.687827: step 611, loss 0.0228113, acc 0.984375\n",
      "2020-06-12T11:50:18.157896: step 612, loss 0.0809663, acc 0.96875\n",
      "2020-06-12T11:50:19.642926: step 613, loss 0.000775525, acc 1\n",
      "2020-06-12T11:50:21.157875: step 614, loss 0.0356578, acc 0.984375\n",
      "2020-06-12T11:50:22.200086: step 615, loss 0.00638585, acc 1\n",
      "2020-06-12T11:50:23.762909: step 616, loss 0.00106896, acc 1\n",
      "2020-06-12T11:50:25.252925: step 617, loss 0.00171722, acc 1\n",
      "2020-06-12T11:50:26.766947: step 618, loss 0.0015548, acc 1\n",
      "2020-06-12T11:50:28.251906: step 619, loss 0.0453583, acc 0.984375\n",
      "2020-06-12T11:50:29.272177: step 620, loss 0.0370091, acc 0.954545\n",
      "2020-06-12T11:50:30.752289: step 621, loss 0.00395803, acc 1\n",
      "2020-06-12T11:50:32.214310: step 622, loss 0.0120987, acc 1\n",
      "2020-06-12T11:50:33.702331: step 623, loss 0.0170089, acc 0.984375\n",
      "2020-06-12T11:50:35.230245: step 624, loss 0.0537156, acc 0.984375\n",
      "2020-06-12T11:50:36.315343: step 625, loss 0.00584493, acc 1\n",
      "2020-06-12T11:50:37.883152: step 626, loss 0.0193567, acc 1\n",
      "2020-06-12T11:50:39.454948: step 627, loss 0.00709053, acc 1\n",
      "2020-06-12T11:50:40.947955: step 628, loss 0.00485031, acc 1\n",
      "2020-06-12T11:50:42.414036: step 629, loss 0.0136114, acc 1\n",
      "2020-06-12T11:50:43.436366: step 630, loss 0.0255841, acc 0.977273\n",
      "2020-06-12T11:50:44.939284: step 631, loss 0.0206176, acc 1\n",
      "2020-06-12T11:50:46.450286: step 632, loss 0.0298646, acc 0.984375\n",
      "2020-06-12T11:50:47.933278: step 633, loss 0.0139049, acc 1\n",
      "2020-06-12T11:50:49.428298: step 634, loss 0.0459783, acc 0.96875\n",
      "2020-06-12T11:50:50.453538: step 635, loss 0.00264164, acc 1\n",
      "2020-06-12T11:50:51.900670: step 636, loss 0.0153911, acc 1\n",
      "2020-06-12T11:50:53.439555: step 637, loss 0.0320242, acc 0.984375\n",
      "2020-06-12T11:50:54.975446: step 638, loss 0.0203189, acc 0.984375\n",
      "2020-06-12T11:50:56.505438: step 639, loss 0.000660346, acc 1\n",
      "2020-06-12T11:50:57.537596: step 640, loss 0.00847507, acc 1\n",
      "2020-06-12T11:50:59.011653: step 641, loss 0.00781552, acc 1\n",
      "2020-06-12T11:51:00.565498: step 642, loss 0.0341898, acc 0.984375\n",
      "2020-06-12T11:51:02.054518: step 643, loss 0.0210323, acc 0.984375\n",
      "2020-06-12T11:51:03.565476: step 644, loss 0.00363757, acc 1\n",
      "2020-06-12T11:51:04.594725: step 645, loss 0.035859, acc 0.977273\n",
      "2020-06-12T11:51:06.048836: step 646, loss 0.00424587, acc 1\n",
      "2020-06-12T11:51:07.504944: step 647, loss 0.0317288, acc 0.984375\n",
      "2020-06-12T11:51:08.988020: step 648, loss 0.00517027, acc 1\n",
      "2020-06-12T11:51:10.595680: step 649, loss 0.0123104, acc 1\n",
      "2020-06-12T11:51:11.643876: step 650, loss 0.0211105, acc 1\n",
      "2020-06-12T11:51:13.176776: step 651, loss 0.000778101, acc 1\n",
      "2020-06-12T11:51:14.653828: step 652, loss 0.0121759, acc 1\n",
      "2020-06-12T11:51:16.167793: step 653, loss 0.00741572, acc 1\n",
      "2020-06-12T11:51:17.649865: step 654, loss 0.0423305, acc 0.984375\n",
      "2020-06-12T11:51:18.686045: step 655, loss 0.0392259, acc 0.977273\n",
      "2020-06-12T11:51:20.188028: step 656, loss 0.00818566, acc 1\n",
      "2020-06-12T11:51:21.640147: step 657, loss 0.0041834, acc 1\n",
      "2020-06-12T11:51:23.123181: step 658, loss 0.00455522, acc 1\n",
      "2020-06-12T11:51:24.596242: step 659, loss 0.00710881, acc 1\n",
      "2020-06-12T11:51:25.669373: step 660, loss 0.00283599, acc 1\n",
      "2020-06-12T11:51:27.256130: step 661, loss 0.00706775, acc 1\n",
      "2020-06-12T11:51:28.737169: step 662, loss 0.0537336, acc 0.96875\n",
      "2020-06-12T11:51:30.210230: step 663, loss 0.0078981, acc 1\n",
      "2020-06-12T11:51:31.699314: step 664, loss 0.0296091, acc 0.984375\n",
      "2020-06-12T11:51:32.714532: step 665, loss 0.0159384, acc 1\n",
      "2020-06-12T11:51:34.189588: step 666, loss 0.0146693, acc 1\n",
      "2020-06-12T11:51:35.669633: step 667, loss 0.0755564, acc 0.984375\n",
      "2020-06-12T11:51:37.196587: step 668, loss 0.0343417, acc 0.984375\n",
      "2020-06-12T11:51:38.658710: step 669, loss 0.0181249, acc 0.984375\n",
      "2020-06-12T11:51:39.663950: step 670, loss 0.0263319, acc 1\n",
      "2020-06-12T11:51:41.139006: step 671, loss 0.00327449, acc 1\n",
      "2020-06-12T11:51:42.678890: step 672, loss 0.00177104, acc 1\n",
      "2020-06-12T11:51:44.203883: step 673, loss 0.00154243, acc 1\n",
      "2020-06-12T11:51:45.699882: step 674, loss 0.00710458, acc 1\n",
      "2020-06-12T11:51:46.726068: step 675, loss 0.0184102, acc 1\n",
      "2020-06-12T11:51:48.191151: step 676, loss 0.00616452, acc 1\n",
      "2020-06-12T11:51:49.646259: step 677, loss 0.00626739, acc 1\n",
      "2020-06-12T11:51:51.117372: step 678, loss 0.00643529, acc 1\n",
      "2020-06-12T11:51:52.586397: step 679, loss 0.0188955, acc 0.984375\n",
      "2020-06-12T11:51:53.750285: step 680, loss 0.0026763, acc 1\n",
      "2020-06-12T11:51:55.203399: step 681, loss 0.0176164, acc 1\n",
      "2020-06-12T11:51:56.718349: step 682, loss 0.00509181, acc 1\n",
      "2020-06-12T11:51:58.279217: step 683, loss 0.0732275, acc 0.96875\n",
      "2020-06-12T11:51:59.809084: step 684, loss 0.00730104, acc 1\n",
      "2020-06-12T11:52:00.823442: step 685, loss 0.0257112, acc 0.977273\n",
      "2020-06-12T11:52:02.297431: step 686, loss 0.000311727, acc 1\n",
      "2020-06-12T11:52:03.812380: step 687, loss 0.00369944, acc 1\n",
      "2020-06-12T11:52:05.287477: step 688, loss 0.0113099, acc 1\n",
      "2020-06-12T11:52:06.775457: step 689, loss 0.0189377, acc 1\n",
      "2020-06-12T11:52:07.799716: step 690, loss 0.00100485, acc 1\n",
      "2020-06-12T11:52:09.250879: step 691, loss 0.0102728, acc 1\n",
      "2020-06-12T11:52:10.737902: step 692, loss 0.00855151, acc 1\n",
      "2020-06-12T11:52:12.190975: step 693, loss 0.000497948, acc 1\n",
      "2020-06-12T11:52:13.754819: step 694, loss 0.127045, acc 0.984375\n",
      "2020-06-12T11:52:14.828922: step 695, loss 0.0139244, acc 1\n",
      "2020-06-12T11:52:16.304974: step 696, loss 0.00312819, acc 1\n",
      "2020-06-12T11:52:17.791001: step 697, loss 0.0022149, acc 1\n",
      "2020-06-12T11:52:19.255159: step 698, loss 0.00584359, acc 1\n",
      "2020-06-12T11:52:20.754078: step 699, loss 0.0395014, acc 0.96875\n",
      "2020-06-12T11:52:21.765444: step 700, loss 0.00368968, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:52:21.887047: step 700, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-700\n",
      "\n",
      "2020-06-12T11:52:23.890689: step 701, loss 0.00879644, acc 1\n",
      "2020-06-12T11:52:25.360830: step 702, loss 0.00558385, acc 1\n",
      "2020-06-12T11:52:26.842797: step 703, loss 0.0553486, acc 0.984375\n",
      "2020-06-12T11:52:28.333859: step 704, loss 0.00708124, acc 1\n",
      "2020-06-12T11:52:29.395969: step 705, loss 0.0447698, acc 0.954545\n",
      "2020-06-12T11:52:30.964775: step 706, loss 0.0325503, acc 0.984375\n",
      "2020-06-12T11:52:32.420882: step 707, loss 0.0568412, acc 0.96875\n",
      "2020-06-12T11:52:33.927851: step 708, loss 0.0341056, acc 0.984375\n",
      "2020-06-12T11:52:35.427841: step 709, loss 0.056696, acc 0.96875\n",
      "2020-06-12T11:52:36.446118: step 710, loss 0.0113401, acc 1\n",
      "2020-06-12T11:52:37.914193: step 711, loss 0.00445978, acc 1\n",
      "2020-06-12T11:52:39.364314: step 712, loss 0.00796373, acc 1\n",
      "2020-06-12T11:52:40.885292: step 713, loss 0.0214172, acc 0.984375\n",
      "2020-06-12T11:52:42.344346: step 714, loss 0.00876584, acc 1\n",
      "2020-06-12T11:52:43.388554: step 715, loss 0.00131057, acc 1\n",
      "2020-06-12T11:52:44.862613: step 716, loss 0.0216247, acc 1\n",
      "2020-06-12T11:52:46.400499: step 717, loss 0.0752635, acc 0.96875\n",
      "2020-06-12T11:52:47.936413: step 718, loss 0.0738548, acc 0.96875\n",
      "2020-06-12T11:52:49.430397: step 719, loss 0.00998744, acc 1\n",
      "2020-06-12T11:52:50.456722: step 720, loss 0.00975299, acc 1\n",
      "2020-06-12T11:52:51.900836: step 721, loss 0.00172826, acc 1\n",
      "2020-06-12T11:52:53.369926: step 722, loss 0.00371556, acc 1\n",
      "2020-06-12T11:52:54.832953: step 723, loss 0.00501102, acc 1\n",
      "2020-06-12T11:52:56.303020: step 724, loss 0.00411775, acc 1\n",
      "2020-06-12T11:52:57.352293: step 725, loss 0.00115596, acc 1\n",
      "2020-06-12T11:52:58.824279: step 726, loss 0.0233861, acc 0.984375\n",
      "2020-06-12T11:53:00.311303: step 727, loss 0.00829221, acc 1\n",
      "2020-06-12T11:53:01.835229: step 728, loss 0.00126747, acc 1\n",
      "2020-06-12T11:53:03.361147: step 729, loss 0.00249194, acc 1\n",
      "2020-06-12T11:53:04.416367: step 730, loss 0.000190027, acc 1\n",
      "2020-06-12T11:53:05.898363: step 731, loss 0.0232971, acc 1\n",
      "2020-06-12T11:53:07.411360: step 732, loss 0.0284307, acc 0.984375\n",
      "2020-06-12T11:53:08.882385: step 733, loss 0.00332834, acc 1\n",
      "2020-06-12T11:53:10.370405: step 734, loss 0.020136, acc 0.984375\n",
      "2020-06-12T11:53:11.409626: step 735, loss 0.0115756, acc 1\n",
      "2020-06-12T11:53:12.902635: step 736, loss 0.0195064, acc 1\n",
      "2020-06-12T11:53:14.399631: step 737, loss 0.0139385, acc 1\n",
      "2020-06-12T11:53:15.864719: step 738, loss 0.024016, acc 0.984375\n",
      "2020-06-12T11:53:17.385646: step 739, loss 0.00405323, acc 1\n",
      "2020-06-12T11:53:18.436836: step 740, loss 0.0563719, acc 0.977273\n",
      "2020-06-12T11:53:19.943807: step 741, loss 0.0025458, acc 1\n",
      "2020-06-12T11:53:21.426882: step 742, loss 0.0520191, acc 0.984375\n",
      "2020-06-12T11:53:22.901896: step 743, loss 0.00155107, acc 1\n",
      "2020-06-12T11:53:24.416845: step 744, loss 0.00206556, acc 1\n",
      "2020-06-12T11:53:25.435178: step 745, loss 0.00745793, acc 1\n",
      "2020-06-12T11:53:26.889235: step 746, loss 0.00231176, acc 1\n",
      "2020-06-12T11:53:28.396210: step 747, loss 0.0360424, acc 0.984375\n",
      "2020-06-12T11:53:29.855303: step 748, loss 0.002502, acc 1\n",
      "2020-06-12T11:53:31.343323: step 749, loss 0.0164591, acc 1\n",
      "2020-06-12T11:53:32.368583: step 750, loss 0.00942079, acc 1\n",
      "2020-06-12T11:53:33.943371: step 751, loss 0.0736394, acc 0.96875\n",
      "2020-06-12T11:53:35.476274: step 752, loss 0.0518723, acc 0.984375\n",
      "2020-06-12T11:53:36.933377: step 753, loss 0.000573318, acc 1\n",
      "2020-06-12T11:53:38.417450: step 754, loss 0.0147928, acc 0.984375\n",
      "2020-06-12T11:53:39.426710: step 755, loss 0.00468654, acc 1\n",
      "2020-06-12T11:53:40.959611: step 756, loss 0.00803255, acc 1\n",
      "2020-06-12T11:53:42.447633: step 757, loss 0.00122856, acc 1\n",
      "2020-06-12T11:53:43.972554: step 758, loss 0.00888618, acc 1\n",
      "2020-06-12T11:53:45.446613: step 759, loss 0.00170657, acc 1\n",
      "2020-06-12T11:53:46.460900: step 760, loss 0.00984466, acc 1\n",
      "2020-06-12T11:53:47.954904: step 761, loss 0.0757643, acc 0.984375\n",
      "2020-06-12T11:53:49.443923: step 762, loss 0.00858483, acc 1\n",
      "2020-06-12T11:53:51.032676: step 763, loss 0.0111428, acc 1\n",
      "2020-06-12T11:53:52.498755: step 764, loss 0.0018052, acc 1\n",
      "2020-06-12T11:53:53.541967: step 765, loss 0.00872484, acc 1\n",
      "2020-06-12T11:53:55.091822: step 766, loss 0.00537546, acc 1\n",
      "2020-06-12T11:53:56.571872: step 767, loss 0.00177103, acc 1\n",
      "2020-06-12T11:53:58.114738: step 768, loss 0.00160534, acc 1\n",
      "2020-06-12T11:53:59.585804: step 769, loss 0.00357591, acc 1\n",
      "2020-06-12T11:54:00.651954: step 770, loss 0.10857, acc 0.977273\n",
      "2020-06-12T11:54:02.124017: step 771, loss 0.0087525, acc 1\n",
      "2020-06-12T11:54:03.624007: step 772, loss 0.0070428, acc 1\n",
      "2020-06-12T11:54:05.131974: step 773, loss 0.00775484, acc 1\n",
      "2020-06-12T11:54:06.658892: step 774, loss 0.00390228, acc 1\n",
      "2020-06-12T11:54:07.680160: step 775, loss 0.00249935, acc 1\n",
      "2020-06-12T11:54:09.205082: step 776, loss 0.000812893, acc 1\n",
      "2020-06-12T11:54:10.694172: step 777, loss 0.00719332, acc 1\n",
      "2020-06-12T11:54:12.162175: step 778, loss 0.0109647, acc 1\n",
      "2020-06-12T11:54:13.623271: step 779, loss 0.0862975, acc 0.953125\n",
      "2020-06-12T11:54:14.643542: step 780, loss 0.023367, acc 1\n",
      "2020-06-12T11:54:16.132630: step 781, loss 0.028904, acc 0.984375\n",
      "2020-06-12T11:54:17.616611: step 782, loss 0.076124, acc 0.984375\n",
      "2020-06-12T11:54:19.108602: step 783, loss 0.00167276, acc 1\n",
      "2020-06-12T11:54:20.591637: step 784, loss 0.0209612, acc 1\n",
      "2020-06-12T11:54:21.644819: step 785, loss 0.0101716, acc 1\n",
      "2020-06-12T11:54:23.198666: step 786, loss 0.0029596, acc 1\n",
      "2020-06-12T11:54:24.691672: step 787, loss 0.00503504, acc 1\n",
      "2020-06-12T11:54:26.158750: step 788, loss 0.0468469, acc 0.984375\n",
      "2020-06-12T11:54:27.664722: step 789, loss 0.00211927, acc 1\n",
      "2020-06-12T11:54:28.710983: step 790, loss 0.00960993, acc 1\n",
      "2020-06-12T11:54:30.190967: step 791, loss 0.0106035, acc 1\n",
      "2020-06-12T11:54:31.618151: step 792, loss 0.0104297, acc 1\n",
      "2020-06-12T11:54:33.105176: step 793, loss 0.0195469, acc 0.984375\n",
      "2020-06-12T11:54:34.618130: step 794, loss 0.00623649, acc 1\n",
      "2020-06-12T11:54:35.645384: step 795, loss 0.000770177, acc 1\n",
      "2020-06-12T11:54:37.131410: step 796, loss 0.018332, acc 0.984375\n",
      "2020-06-12T11:54:38.672289: step 797, loss 0.00108111, acc 1\n",
      "2020-06-12T11:54:40.177265: step 798, loss 0.00903501, acc 1\n",
      "2020-06-12T11:54:41.682241: step 799, loss 0.00230367, acc 1\n",
      "2020-06-12T11:54:42.679572: step 800, loss 0.000948801, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:54:42.800250: step 800, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-800\n",
      "\n",
      "2020-06-12T11:54:44.693190: step 801, loss 0.0108759, acc 1\n",
      "2020-06-12T11:54:46.171238: step 802, loss 0.0169889, acc 1\n",
      "2020-06-12T11:54:47.670271: step 803, loss 0.0105329, acc 1\n",
      "2020-06-12T11:54:49.162239: step 804, loss 0.00123338, acc 1\n",
      "2020-06-12T11:54:50.181575: step 805, loss 0.0013134, acc 1\n",
      "2020-06-12T11:54:51.654646: step 806, loss 0.00182859, acc 1\n",
      "2020-06-12T11:54:53.172515: step 807, loss 0.0467242, acc 0.984375\n",
      "2020-06-12T11:54:54.768249: step 808, loss 0.0710778, acc 0.984375\n",
      "2020-06-12T11:54:56.266243: step 809, loss 0.0255595, acc 0.984375\n",
      "2020-06-12T11:54:57.325410: step 810, loss 0.0384666, acc 0.977273\n",
      "2020-06-12T11:54:58.783513: step 811, loss 0.00474301, acc 1\n",
      "2020-06-12T11:55:00.260562: step 812, loss 0.000490328, acc 1\n",
      "2020-06-12T11:55:01.706696: step 813, loss 0.0130226, acc 1\n",
      "2020-06-12T11:55:03.154823: step 814, loss 0.0058502, acc 1\n",
      "2020-06-12T11:55:04.218978: step 815, loss 0.0345697, acc 0.977273\n",
      "2020-06-12T11:55:05.667105: step 816, loss 0.000861719, acc 1\n",
      "2020-06-12T11:55:07.191032: step 817, loss 0.00614526, acc 1\n",
      "2020-06-12T11:55:08.661100: step 818, loss 0.00251738, acc 1\n",
      "2020-06-12T11:55:10.221926: step 819, loss 0.00186665, acc 1\n",
      "2020-06-12T11:55:11.284086: step 820, loss 0.00309554, acc 1\n",
      "2020-06-12T11:55:12.791133: step 821, loss 0.0142784, acc 0.984375\n",
      "2020-06-12T11:55:14.315024: step 822, loss 0.000484219, acc 1\n",
      "2020-06-12T11:55:15.783056: step 823, loss 0.000951817, acc 1\n",
      "2020-06-12T11:55:17.289029: step 824, loss 0.00101208, acc 1\n",
      "2020-06-12T11:55:18.297332: step 825, loss 0.00194798, acc 1\n",
      "2020-06-12T11:55:19.788388: step 826, loss 0.000714377, acc 1\n",
      "2020-06-12T11:55:21.299306: step 827, loss 0.00112714, acc 1\n",
      "2020-06-12T11:55:22.764389: step 828, loss 0.00425233, acc 1\n",
      "2020-06-12T11:55:24.292302: step 829, loss 0.00322073, acc 1\n",
      "2020-06-12T11:55:25.334517: step 830, loss 0.00851362, acc 1\n",
      "2020-06-12T11:55:26.895342: step 831, loss 0.00824128, acc 1\n",
      "2020-06-12T11:55:28.369399: step 832, loss 0.00258474, acc 1\n",
      "2020-06-12T11:55:29.859416: step 833, loss 0.000277631, acc 1\n",
      "2020-06-12T11:55:31.348435: step 834, loss 0.00435298, acc 1\n",
      "2020-06-12T11:55:32.369704: step 835, loss 0.0258939, acc 1\n",
      "2020-06-12T11:55:33.862711: step 836, loss 0.0339182, acc 0.96875\n",
      "2020-06-12T11:55:35.350733: step 837, loss 0.0334773, acc 0.984375\n",
      "2020-06-12T11:55:36.822826: step 838, loss 0.0141749, acc 0.984375\n",
      "2020-06-12T11:55:38.307874: step 839, loss 0.00525519, acc 1\n",
      "2020-06-12T11:55:39.320118: step 840, loss 0.018798, acc 0.977273\n",
      "2020-06-12T11:55:40.821105: step 841, loss 0.000281876, acc 1\n",
      "2020-06-12T11:55:42.307131: step 842, loss 0.0717292, acc 0.984375\n",
      "2020-06-12T11:55:43.883914: step 843, loss 0.0454052, acc 0.984375\n",
      "2020-06-12T11:55:45.331045: step 844, loss 0.0114754, acc 1\n",
      "2020-06-12T11:55:46.352382: step 845, loss 0.00250659, acc 1\n",
      "2020-06-12T11:55:47.854297: step 846, loss 0.00188724, acc 1\n",
      "2020-06-12T11:55:49.330352: step 847, loss 0.0128789, acc 0.984375\n",
      "2020-06-12T11:55:50.884197: step 848, loss 0.00376791, acc 1\n",
      "2020-06-12T11:55:52.407123: step 849, loss 0.00764273, acc 1\n",
      "2020-06-12T11:55:53.455322: step 850, loss 0.000699457, acc 1\n",
      "2020-06-12T11:55:54.935405: step 851, loss 0.000688764, acc 1\n",
      "2020-06-12T11:55:56.548052: step 852, loss 0.0143786, acc 0.984375\n",
      "2020-06-12T11:55:58.141790: step 853, loss 0.00599391, acc 1\n",
      "2020-06-12T11:55:59.701620: step 854, loss 0.000955627, acc 1\n",
      "2020-06-12T11:56:00.729940: step 855, loss 0.000983886, acc 1\n",
      "2020-06-12T11:56:02.205924: step 856, loss 0.00248716, acc 1\n",
      "2020-06-12T11:56:03.696935: step 857, loss 0.000928698, acc 1\n",
      "2020-06-12T11:56:05.190941: step 858, loss 0.000952856, acc 1\n",
      "2020-06-12T11:56:06.696914: step 859, loss 0.0106312, acc 1\n",
      "2020-06-12T11:56:07.687265: step 860, loss 0.00105615, acc 1\n",
      "2020-06-12T11:56:09.170300: step 861, loss 0.0126851, acc 1\n",
      "2020-06-12T11:56:10.669292: step 862, loss 0.0120873, acc 1\n",
      "2020-06-12T11:56:12.143421: step 863, loss 0.00178296, acc 1\n",
      "2020-06-12T11:56:13.705216: step 864, loss 0.0222285, acc 0.984375\n",
      "2020-06-12T11:56:14.769330: step 865, loss 0.0468635, acc 0.977273\n",
      "2020-06-12T11:56:16.282282: step 866, loss 0.000517808, acc 1\n",
      "2020-06-12T11:56:17.759334: step 867, loss 0.00131944, acc 1\n",
      "2020-06-12T11:56:19.225412: step 868, loss 0.00646683, acc 1\n",
      "2020-06-12T11:56:20.728394: step 869, loss 0.00309349, acc 1\n",
      "2020-06-12T11:56:21.746749: step 870, loss 0.000506694, acc 1\n",
      "2020-06-12T11:56:23.234692: step 871, loss 0.0390827, acc 0.984375\n",
      "2020-06-12T11:56:24.706756: step 872, loss 0.0010433, acc 1\n",
      "2020-06-12T11:56:26.172836: step 873, loss 0.00445468, acc 1\n",
      "2020-06-12T11:56:27.656868: step 874, loss 0.000712837, acc 1\n",
      "2020-06-12T11:56:28.672152: step 875, loss 0.00112477, acc 1\n",
      "2020-06-12T11:56:30.233054: step 876, loss 0.00265752, acc 1\n",
      "2020-06-12T11:56:31.722996: step 877, loss 0.0047313, acc 1\n",
      "2020-06-12T11:56:33.191070: step 878, loss 0.00544037, acc 1\n",
      "2020-06-12T11:56:34.698040: step 879, loss 0.000816153, acc 1\n",
      "2020-06-12T11:56:35.717313: step 880, loss 0.00313695, acc 1\n",
      "2020-06-12T11:56:37.219299: step 881, loss 0.00388742, acc 1\n",
      "2020-06-12T11:56:38.697345: step 882, loss 0.00441439, acc 1\n",
      "2020-06-12T11:56:40.202322: step 883, loss 0.0214609, acc 1\n",
      "2020-06-12T11:56:41.670395: step 884, loss 0.00917421, acc 1\n",
      "2020-06-12T11:56:42.680694: step 885, loss 0.000378548, acc 1\n",
      "2020-06-12T11:56:44.180683: step 886, loss 0.0223872, acc 0.984375\n",
      "2020-06-12T11:56:45.742508: step 887, loss 0.00527989, acc 1\n",
      "2020-06-12T11:56:47.324278: step 888, loss 0.0317375, acc 0.984375\n",
      "2020-06-12T11:56:48.788363: step 889, loss 0.00151025, acc 1\n",
      "2020-06-12T11:56:49.825589: step 890, loss 0.000817719, acc 1\n",
      "2020-06-12T11:56:51.299690: step 891, loss 0.00575504, acc 1\n",
      "2020-06-12T11:56:52.762736: step 892, loss 0.000823024, acc 1\n",
      "2020-06-12T11:56:54.274692: step 893, loss 0.00787594, acc 1\n",
      "2020-06-12T11:56:55.735827: step 894, loss 0.00253287, acc 1\n",
      "2020-06-12T11:56:56.783983: step 895, loss 0.0088052, acc 1\n",
      "2020-06-12T11:56:58.276989: step 896, loss 0.00599331, acc 1\n",
      "2020-06-12T11:56:59.772991: step 897, loss 0.000933154, acc 1\n",
      "2020-06-12T11:57:01.277967: step 898, loss 0.000548364, acc 1\n",
      "2020-06-12T11:57:02.791918: step 899, loss 0.00262213, acc 1\n",
      "2020-06-12T11:57:03.840115: step 900, loss 0.00274656, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:57:03.959794: step 900, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-900\n",
      "\n",
      "2020-06-12T11:57:05.804861: step 901, loss 0.00163369, acc 1\n",
      "2020-06-12T11:57:07.304926: step 902, loss 0.0132126, acc 1\n",
      "2020-06-12T11:57:08.810824: step 903, loss 0.0118602, acc 0.984375\n",
      "2020-06-12T11:57:10.301835: step 904, loss 0.000517887, acc 1\n",
      "2020-06-12T11:57:11.333078: step 905, loss 0.0179154, acc 1\n",
      "2020-06-12T11:57:12.809133: step 906, loss 0.0252573, acc 0.984375\n",
      "2020-06-12T11:57:14.318097: step 907, loss 0.00739044, acc 1\n",
      "2020-06-12T11:57:15.787171: step 908, loss 0.00116682, acc 1\n",
      "2020-06-12T11:57:17.319071: step 909, loss 0.039922, acc 0.984375\n",
      "2020-06-12T11:57:18.398188: step 910, loss 0.00648581, acc 1\n",
      "2020-06-12T11:57:19.918122: step 911, loss 0.00507026, acc 1\n",
      "2020-06-12T11:57:21.405147: step 912, loss 0.00715441, acc 1\n",
      "2020-06-12T11:57:22.879206: step 913, loss 0.00591362, acc 1\n",
      "2020-06-12T11:57:24.396147: step 914, loss 0.0134902, acc 0.984375\n",
      "2020-06-12T11:57:25.427391: step 915, loss 0.00864915, acc 1\n",
      "2020-06-12T11:57:26.896463: step 916, loss 0.000390981, acc 1\n",
      "2020-06-12T11:57:28.373514: step 917, loss 0.00615504, acc 1\n",
      "2020-06-12T11:57:29.851562: step 918, loss 0.00467976, acc 1\n",
      "2020-06-12T11:57:31.379475: step 919, loss 0.00166486, acc 1\n",
      "2020-06-12T11:57:32.402739: step 920, loss 0.00248288, acc 1\n",
      "2020-06-12T11:57:33.943619: step 921, loss 0.0184949, acc 0.984375\n",
      "2020-06-12T11:57:35.492476: step 922, loss 0.00022718, acc 1\n",
      "2020-06-12T11:57:36.942600: step 923, loss 0.00747018, acc 1\n",
      "2020-06-12T11:57:38.425635: step 924, loss 0.000550445, acc 1\n",
      "2020-06-12T11:57:39.438925: step 925, loss 0.0141841, acc 1\n",
      "2020-06-12T11:57:40.926945: step 926, loss 0.000764452, acc 1\n",
      "2020-06-12T11:57:42.401003: step 927, loss 0.000529385, acc 1\n",
      "2020-06-12T11:57:43.884037: step 928, loss 0.00056588, acc 1\n",
      "2020-06-12T11:57:45.376064: step 929, loss 0.0776353, acc 0.984375\n",
      "2020-06-12T11:57:46.393329: step 930, loss 0.000392678, acc 1\n",
      "2020-06-12T11:57:47.910317: step 931, loss 0.0139729, acc 1\n",
      "2020-06-12T11:57:49.459130: step 932, loss 0.00417348, acc 1\n",
      "2020-06-12T11:57:51.027937: step 933, loss 0.00105306, acc 1\n",
      "2020-06-12T11:57:52.508977: step 934, loss 0.00270459, acc 1\n",
      "2020-06-12T11:57:53.538224: step 935, loss 0.00478623, acc 1\n",
      "2020-06-12T11:57:55.053173: step 936, loss 0.0050747, acc 1\n",
      "2020-06-12T11:57:56.661871: step 937, loss 0.0114724, acc 1\n",
      "2020-06-12T11:57:58.171896: step 938, loss 0.00582202, acc 1\n",
      "2020-06-12T11:57:59.627005: step 939, loss 0.000819428, acc 1\n",
      "2020-06-12T11:58:00.670152: step 940, loss 0.00245984, acc 1\n",
      "2020-06-12T11:58:02.158245: step 941, loss 0.00168203, acc 1\n",
      "2020-06-12T11:58:03.641208: step 942, loss 0.000929484, acc 1\n",
      "2020-06-12T11:58:05.156158: step 943, loss 0.00888461, acc 1\n",
      "2020-06-12T11:58:06.708051: step 944, loss 0.00678755, acc 1\n",
      "2020-06-12T11:58:07.760194: step 945, loss 0.000482473, acc 1\n",
      "2020-06-12T11:58:09.218296: step 946, loss 0.000978658, acc 1\n",
      "2020-06-12T11:58:10.720280: step 947, loss 0.0112813, acc 1\n",
      "2020-06-12T11:58:12.194381: step 948, loss 0.00264985, acc 1\n",
      "2020-06-12T11:58:13.654432: step 949, loss 0.00156237, acc 1\n",
      "2020-06-12T11:58:14.706620: step 950, loss 0.00374552, acc 1\n",
      "2020-06-12T11:58:16.186661: step 951, loss 0.0194713, acc 0.984375\n",
      "2020-06-12T11:58:17.678767: step 952, loss 0.00447703, acc 1\n",
      "2020-06-12T11:58:19.142799: step 953, loss 0.0271174, acc 0.984375\n",
      "2020-06-12T11:58:20.612826: step 954, loss 0.0475039, acc 0.984375\n",
      "2020-06-12T11:58:21.694933: step 955, loss 0.0229351, acc 0.977273\n",
      "2020-06-12T11:58:23.215866: step 956, loss 0.018392, acc 0.984375\n",
      "2020-06-12T11:58:24.739867: step 957, loss 0.00174102, acc 1\n",
      "2020-06-12T11:58:26.208909: step 958, loss 0.00507272, acc 1\n",
      "2020-06-12T11:58:27.698880: step 959, loss 0.000144219, acc 1\n",
      "2020-06-12T11:58:28.713166: step 960, loss 0.000258284, acc 1\n",
      "2020-06-12T11:58:30.199192: step 961, loss 0.00206261, acc 1\n",
      "2020-06-12T11:58:31.687214: step 962, loss 0.00149488, acc 1\n",
      "2020-06-12T11:58:33.182217: step 963, loss 0.00597718, acc 1\n",
      "2020-06-12T11:58:34.691181: step 964, loss 0.0165746, acc 0.984375\n",
      "2020-06-12T11:58:35.713448: step 965, loss 0.00298328, acc 1\n",
      "2020-06-12T11:58:37.214436: step 966, loss 0.0131267, acc 1\n",
      "2020-06-12T11:58:38.772269: step 967, loss 0.0029894, acc 1\n",
      "2020-06-12T11:58:40.281270: step 968, loss 0.00180715, acc 1\n",
      "2020-06-12T11:58:41.777304: step 969, loss 0.00419914, acc 1\n",
      "2020-06-12T11:58:42.808476: step 970, loss 0.00182833, acc 1\n",
      "2020-06-12T11:58:44.288589: step 971, loss 0.00242907, acc 1\n",
      "2020-06-12T11:58:45.799487: step 972, loss 0.0714105, acc 0.984375\n",
      "2020-06-12T11:58:47.274535: step 973, loss 0.00218395, acc 1\n",
      "2020-06-12T11:58:48.726694: step 974, loss 0.00281553, acc 1\n",
      "2020-06-12T11:58:49.740940: step 975, loss 0.000962497, acc 1\n",
      "2020-06-12T11:58:51.239931: step 976, loss 0.0031244, acc 1\n",
      "2020-06-12T11:58:52.731942: step 977, loss 0.000598371, acc 1\n",
      "2020-06-12T11:58:54.269830: step 978, loss 0.000623659, acc 1\n",
      "2020-06-12T11:58:55.808715: step 979, loss 0.00124101, acc 1\n",
      "2020-06-12T11:58:56.808043: step 980, loss 0.00221126, acc 1\n",
      "2020-06-12T11:58:58.327977: step 981, loss 0.0377233, acc 0.984375\n",
      "2020-06-12T11:58:59.815999: step 982, loss 0.0317927, acc 0.984375\n",
      "2020-06-12T11:59:01.355953: step 983, loss 0.00633421, acc 1\n",
      "2020-06-12T11:59:02.855942: step 984, loss 0.0261415, acc 0.984375\n",
      "2020-06-12T11:59:03.867167: step 985, loss 0.0186599, acc 1\n",
      "2020-06-12T11:59:05.373139: step 986, loss 0.00167389, acc 1\n",
      "2020-06-12T11:59:06.847199: step 987, loss 0.000567488, acc 1\n",
      "2020-06-12T11:59:08.338212: step 988, loss 0.000793079, acc 1\n",
      "2020-06-12T11:59:09.900069: step 989, loss 0.0103101, acc 1\n",
      "2020-06-12T11:59:10.980146: step 990, loss 0.0119663, acc 1\n",
      "2020-06-12T11:59:12.475150: step 991, loss 0.0498345, acc 0.984375\n",
      "2020-06-12T11:59:13.953246: step 992, loss 0.00827754, acc 1\n",
      "2020-06-12T11:59:15.449268: step 993, loss 0.00493016, acc 1\n",
      "2020-06-12T11:59:16.916272: step 994, loss 0.00230247, acc 1\n",
      "2020-06-12T11:59:17.965467: step 995, loss 0.00833159, acc 1\n",
      "2020-06-12T11:59:19.435536: step 996, loss 0.000633212, acc 1\n",
      "2020-06-12T11:59:20.933532: step 997, loss 0.00641841, acc 1\n",
      "2020-06-12T11:59:22.412576: step 998, loss 0.00896113, acc 1\n",
      "2020-06-12T11:59:23.889697: step 999, loss 0.00563582, acc 1\n",
      "2020-06-12T11:59:24.959765: step 1000, loss 0.00132247, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-06-12T11:59:25.090416: step 1000, loss nan, acc 0.333333\n",
      "\n",
      "Saved model checkpoint to D:\\mekoh\\bluehouse\\text-cnn-tf\\cnn-text-classification-tf\\runs\\1591929347\\checkpoints\\model-1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
